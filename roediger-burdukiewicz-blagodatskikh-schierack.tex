% !TeX root = RJwrapper.tex
\title{R as an Environment for the Analysis of dPCR and qPCR Experiments}
\author{by Stefan R\"{o}diger, Micha\l{} Burdukiewicz, Konstantin 
Blagodatskikh and Peter Schierack}

\maketitle

\abstract{
There is an ever-increasing number of applications, which use quantitative PCR 
(qPCR) or digital PCR (dPCR) to elicit fundamentals of biological processes. 
Moreover, the novel amplification strategies based on quantitative isothermal 
amplification (qIA) have become more prominent in life sciences and 
point-of-care-diagnostics. Additionally, the analysis of melting data is 
essential during many experiments. Several software packages have been 
developed 
for the analysis of such data sets. In most cases, the software is either 
distributed as closed source software or as monolithic block with little 
freedom 
to perform highly customized analysis procedures. Others and we argue that R is 
an excellent foundation for reproducible and transparent data analysis in a 
highly customizable cross-platform environment. However, for novices it is 
often 
challenging to master R or learn capabilities of the vast number of packages 
available. In the paper, we describe exemplary workflows for the analysis of 
qPCR, qIA or dPCR experiments including the analysis of melting curve data. Our 
analysis relies entirely on R packages available from public repositories. 
Additionally, we provide information related to standardized and reproducible 
research with R.
}

\section{Introduction}

The quantitative Polymerase Chain Reaction (qPCR) is the method of choice when 
a 
precise quantification of minute DNA traces is required. The applications 
include 
the detection and quantification of pathogens or gene expression analysis 
\citep{peirson_2003}. Only few bioanalytical appliances had such a 
significant impact on the progress of life sciences and medical sciences as the 
qPCR \citep{huggett_qpcr_2015}. Numerous commercial and experimental monitoring 
platforms 
have been developed in the past years. This includes standard plate cyclers, 
capillary cyclers, microfluidic platforms and related technologies 
\citep{rodiger_highly_2013, viturro_2014, rodiger_nucleic_2014, 
khodakov_2014, wu_2014}.

In the past decades several isothermal amplification technologies
emerged, such as helicase 
dependent amplification (HDA), as alternative to PCR. The isothermal 
amplification 
was readily combined with real-time monitoring technologies (qIA) or digital PCR and is used 
nowadays in various fields like diagnostics and point-of-care-testing 
\citep{selck_2013, rodiger_nucleic_2014, nixon_2014}.

The digital PCR (dPCR) is a novel approach for detection and quantification of 
nucleic acids and can be seen as a next generation method 
\citep{huggett_qpcr_2015}. The dPCR technology 
breaks fundamentally with the previous concept of nucleic acid quantification. 
The key difference between dPCR and traditional qPCR lies in the method of 
measuring (absolute) nucleic acids amounts, which yields discrete information 
instead of the continuous signal. This is possible after ``clonal DNA 
amplification'' in thousands of small separated partitions (e.g., droplets, 
nano 
chambers) \citep{huggett_2013, milbury_2014, morley_2014}. The partitions with 
no 
nucleic acid remain negative and the others turn positive (e.g., 
Figure~\ref{figure:dpcR_sim}). Selected technologies (e.g., 
OpenArray\textregistered Real-Time PCR System) monitor amplification reactions 
in the chambers (``partition'') in real-time. After that, all Cq values are 
calculated from the amplification curves and converted into discrete events by 
means of positive and negative chambers. Finally, the absolute quantification 
of 
nucleic acids is done using Poisson statistics. Recently, we have published the 
\CRANpkg{dpcR} package at CRAN, which is the first 
open source R software package for the analysis of dPCR 
experiments (see \CRANpkg{dpcR} for details).

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14cm]{figures/dpcR_sim.pdf}
  \caption{Scheme of droplet digital PCR experiment. \strong{(A)} A droplet 
digital PCR reaction mix was formed in a Bio-Rad QX100 system. The droplets 
(circa 100 $\mu$m in diameter) were subjected to custom made slide chambers for 
the detection and analysis in fully automatized imaging VideoScan platform
\citep{rodiger_highly_2013}. \strong{(B)} Subsequently the samples can be 
digitalized by counting number of positive and total number of droplets. The 
plot was generated with the \code{sim\_ddpcr} function from the \CRANpkg{dpcR} 
package.}
\label{figure:dpcR_sim}
\end{figure}

Many of the commercial and experimental hardware platforms provide means to 
analyse the data. The complexity of hardware, wetware and software requires 
expertise to master a workflow. This comprises standards for experiment design, 
generation and analysis of data, multiple hypothesis testing, interpretation, 
reporting and storage of 
results \citep{huggett_BDQ_2014, conde_2014}. The scientific misconduct and 
fraud have shaken 
the scientific community on several occasions \citep{bustin_2014}. In 
particular, 
the scientific community works hard to uncover pitfalls of qPCR experiments. 
This 
lead to the development of peer-reviewed quantification cycle (Cq) analysis 
algorithms \citep{ruijter_2013}, throughout characterized qPCR chemistries 
\citep{ruijter_2014} and guidelines for a proper conduct of qPCR experiments as 
implemented in the MIQE guidelines (minimum information for publication of 
quantitative real-time PCR experiments) \citep{huggett_2013, bustin_2014}. 
We share the philosophy of the MIQE guidelines to increase the experimental 
transparency for better experimental practice and reliable interpretation of 
results and encourage the use of open data exchange formats like the XML-based 
Real-Time PCR Data Markup Language (RDML) \citep{lefever_2009}. We see the 
application of R in line with this philosophy. 

In case of closed source software the analysis usually happens in a black~box 
fashion tied to a specific platform. We agree that nontransparent frameworks are 
not necessarily a bad thing, but should be avoided if possible 
\citep{roediger_RJ_2013, Spiess_2014}. Studies by \citet{mccullough_2008, 
Almiron_2010, Duran_2014} exemplified where the black~box approach might fail in 
science. The same holds true for the open~source software since software bugs 
are independent of a development model. However, at least open~source gives the 
possibility to track and eliminate errors by an individual entity. 

Black-box systems often force the user to process the data by suboptimal 
analysis algorithms \citep{ruijter_2013}. Moreover, the data usually cannot be 
accessed between the steps of the analysis which restrains quality control. The 
visualization options are usually limited by the software vendor preferences and 
do not attain publication quality. In addition to this, users who have no access 
to the commercial software are barred. 

Aside from closed source software, data analysis is often performed in 
spreadsheets. However, this data processing approach is not advisable for 
research purposes. Most spreadsheets  lack (or do not use) tools to validate the 
input, to debug implemented procedures and to automatize the workflow. These 
traits make them prone to errors and not well suited for complicated tasks 
\citep{mccullough_2008, burns_2014}.

For several reasons, R is one of the most popular tools in bioinformatics and 
is 
known as an early adopter of emerging technologies \citep{pabinger_2014}. R 
provides packages to build highly customized workflows, covering: data 
read-in, data preprocessing, analysis, post-processing, visualization and 
storage. As recently briefly reviewed in \citet{pabinger_2014}, numerous R 
packages have been developed for the analysis of qPCR, dPCR, qIA and melting 
curve analysis experiments, including: \CRANpkg{kulife}, \CRANpkg{MCMC.qpcr}, 
\CRANpkg{qPCR.CT}, \CRANpkg{DivMelt}, \CRANpkg{qpcR}, \CRANpkg{dpcR}, 
\CRANpkg{chipPCR}, \CRANpkg{MBmca}, \CRANpkg{RDML}, \BIOpkg{nondetects}, 
\BIOpkg{qpcrNorm}, \BIOpkg{HTqPCR}, \BIOpkg{SLqPCR}, \BIOpkg{ddCt}, 
\BIOpkg{EasyqpcR}, \BIOpkg{unifiedWMWqPCR}, \BIOpkg{ReadqPCR}, 
\BIOpkg{NormqPCR}. All the packages are either available from CRAN or 
Bioconductor \citep{gentleman_2004}. The packages can be freely combined in a 
plugin-like architecture. The R is an independent, cross-platform analysis 
platform and 
provides a broad spectrum of calculation options. Particularly, the 
visualization of 
experiments is one of R's pinnacles. R enables the users to create an 
efficient manipulation, restructuring and reshaping of data to make them 
readily-available for further processing. This is of the particular importance 
to 
the human -- machine interface \citep{Oh_2014}. The intrinsic properties of R 
such as the naming convention \citep{Baaaath_2012} and class systems (e.g., 
\strong{S3}, \strong{S4}, reference classes and \strong{R6}) vary considerable, 
depending on the package developer preferences. However, due to the open source 
approach, there is the common ground to track numerical errors. R offers 
various 
methods for a standardized data import/export and exchange. Workflows can embed 
structured models \citet{Guazzelli_2009}, open data exchange formats (e.g., 
RDML) , binary 
formats \citep{michna_2013} or tools provided by the R workspace 
\citep{RDCT2010c}. Additionally, the R environment offers several data sets, 
which can be used for testing of algorithms. Therefore, others and we argue 
that 
R is suitable for reproducible research \citep{Murrell_2012, 
gandrud_2013, hofmann_2013, kuhn_cran_2014, Leeper_2014, liu_2014}. 

The aim of this paper is to show case studies for qPCR, dPCR, qIA and melting 
curve analysis experiments. Our workflow effectively follows the principle 
illustrated in Figure~\ref{figure:workflow}. We intend to aggregate 
functionalities dispersed between various packages and offer a fast insight in 
the analysis of nucleic acid experiments with R. In particular, we describe how 
to:

\begin{itemize}
 \item read-in data from a standardized file format,
 \item pre-process the amplification curve data,
 \item calculate specific parameters from the amplification curve data,
 \item calculate the melting temperature,
 \item and report the data.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics{figures/workflow.png}
  \caption{Exemplary workflow for quantitative PCR, digital PCR, quantitative 
isothermal amplification and melting curve analysis experiments in R. Core 
functionality is provided by the R software environment for statistical 
computing and graphics. In our scenario we used the \CRANpkg{RDML} package to 
read-in data in standardized format. However, any format supported by R can be 
used. Further, processing of amplification curve data was performed with the 
\CRANpkg{chipPCR} package and melting curve data were analysed with the 
\CRANpkg{MBmca} package. The \CRANpkg{dpcR} package can be embedded in the 
analysis of digital PCR experiments. Cq, quantification cycle; $T_{M}$, melting 
temperature. 
} 
\label{figure:workflow}
\end{figure}

\section{Setting-up a working environment}

We recommend performing the scripting in a dedicated integrated development 
environment (IDE) and graphical user interface (GUI) such as \pkg{RKWard} 
\citep{rodiger_rkward_2012}, 
\pkg{Rstudio}\footnote{\url{http://www.rstudio.com/}} or related technologies 
\citep{Valero_2012}. Benefits of IDE's with GUI include syntax-highlighting, 
auto completion and function references for rapid prototyping of workflows.

Typically, the analysis will start with data from a commercial platform. 
Most platforms have an option to export a CSV file or spreadsheets application 
file (e.g., *.xls, *.odt). The details for the data import have been described 
elsewhere \citep{RDCT2010c, rodiger_rkward_2012}. To keep the case study 
sections compact we have chosen to load datasets from the \CRANpkg{qpcR} 
package 
\citep{ritz_2008, spiess_2008} (v.~1.4.0) and the \CRANpkg{RDML} package 
(v.~0.4-2) to our workspace. The \CRANpkg{chipPCR} package 
\citep{roediger_2015_Bioinformatics} (v.~0.0.8-8) was used 
for data preprocessing, quality control and  the calculation of the 
quantification cycle (Cq). The Cq is a quantitative measure, which represents 
the number of cycles needed to reach a user defined threshold signal level, in 
the exponential phase of a qPCR/qIA reaction. Several Cq methods have been 
described \citep{ruijter_2013}. In this study we have chosen the second 
derivative maximum method ($Cq_{SDM}$) and the ``Cycle threshold'' ($Cq_{Ct}$) 
method.

During a perfect qPCR reaction, the target DNA doubles ($2^{n}$; n = cycle 
number) at each cycle. Here the amplification efficiency ($AE$) is 100~\%. 
However, in reality, numerous factors cause an inhibition of the amplification 
($AE$ < 100~\%). The $AE$ can be determined by the relation of the Cq value 
depending on the sample input quantity as described in 
\citet{roediger_2015_Bioinformatics, svec_2015}.

In \citet{roediger_RJ_2013} we described the application of R for the analysis 
of melting curve experiments from microbead-based assays. Since the 
mathematical 
foundation for melting curve analysis (MCA) is identical between all platforms 
we applied the functions from the \CRANpkg{MBmca} package (0.0.3-4) for an 
analysis of the target specific melting temperature ($T_{M}$) in experiments of 
the present study.

We completed our examples with case studies for the analysis of dPCR 
experiments. In particular, we used the \CRANpkg{dpcR} package (0.1.4.0) to 
estimate the number of molecules in a sample.

\section{Results}

In the following sections we will show how R can be used (I) as a unified open 
software for data analysis and presentation in research, 
(II) as software frame-work for novel technical developments, (III) as platform 
for teaching of new technologies and (IV) as reference for statistical methods.

\subsection{Case study one -- qPCR and Amplification Efficiency Calculation}

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14cm]{figures/dilution_Cq.pdf}
  \caption{Analysis of the amplification curve data of the \texttt{guescini1} 
dataset. \strong{(A)} Raw data from the calibration curve samples were visually 
inspected. The qPCR curves display a broad variation in plateau fluorescence 
(38~--~62 RFU). The red horizontal line indicates the fluorescence level (0.05) 
used for the calculation of the Cq value by the ``cycle threshold'' method. 
\strong{(B)} The \code{CPP} function from the \CRANpkg{chipPCR} was used to 
baseline the data, to smooth the data with Savitzky-Golay smoothing filter and 
to normalize the data between 0 and 1. \strong{(C)} The Cq values were 
calculated by the $Cq_{SDM}$ method (``SDM method'') (\code{inder}, 
\CRANpkg{chipPCR}) and the $Cq_{Ct}$ method (``Ct method'') (\code{th.cyc}, 
\CRANpkg{chipPCR}). The threshold value was set to $r~=~0.05$. The $Cq_{SDM}$ 
and $Cq_{Ct}$ values were plotted and analysed by a linear regression 
($R^{2}~=~0.9945$; $P < 2.2^{-16}$) and Pearson's ($r~=~0.9972605$; $P < 
2.2^{-16}$). The $AE$ based on \strong{(D)} $Cq_{Ct}$ values and \strong{(E)} 
$Cq_{SDM}$ values were automatically analysed with the \code{effcalc} 
(\CRANpkg{chipPCR}) function.}
  \label{figure:dilution_Cq}
\end{figure}

The goal of our fist case study was to calculate the Cq values and the $AE$ 
from 
a qPCR experiment. We used the ``guescini1'' dataset from the \CRANpkg{qpcR} 
package, where the gene \textit{NADH dehydrogenase 1} (MT-ND1) was amplified in 
a LightCycler\circledR~480 (Roche) thermocycler. Details of the experiment are 
described in \citet{guescini_2008}. First we started with loading the required 
packages and datasets. A good practice for reproducible research is to track 
the 
package versions and environment used during the analysis. The function 
$sessionInfo()$ from the \CRANpkg{utils} package provides this information. 
Assuming that the analysis starts with a clean R session it is possible to 
assign the required packages to an object, as shown below. The reproducibility 
of research can be further improved by the \CRANpkg{archivist} package, which 
stores and recovers crucial data and preserves metadata of saved objects (not 
shown). All settings of R session can be easily saved and/or restored using 
\CRANpkg{settings} package.

\begin{example}
# Load the required packages for the data import and analysis.
# Load the chipPCR package for the pre-processing and curve data quality
# analysis and load the qpcR package as data resource.
require(chipPCR)
require(qpcR)

# Collect information about the R session used for the analysis of the
# experiment.
current.session <- sessionInfo()

# Next load the 'guescini1' dataset from the qpcR package to the
# workspace and assign it to the object 'gue'.
gue <- guescini1

# Define the dilution of the sample DNA quantity for the calibration curve 
# and assign it to the object 'dil'.
dil <- 10^(2: -4)
\end{example}

We previewed the amplification curve raw data using the \code{matplot} 
function (see code below). The amplification curve data showed a strong signal 
level variation in the plateau region (Figure~~\ref{figure:dilution_Cq}A). 
Therefore, all data were subjected to a minimum-maximum normalization (see 
\citet{roediger_RJ_2013}) using the \code{CPP} function from the 
\CRANpkg{chipPCR} package. In addition, all data were baselined and smoothed 
(Figure~~\ref{figure:dilution_Cq}B). The Cq values were calculated by the 
$Cq_{SDM}$ and $Cq_{Ct}$ methods as shown next.

\begin{example}
# Pre-process the amplification curve data with the CPP function from the 
# chipPCR package. The trans parameter was set TRUE to perform a baselining and 
# the method.norm parameter was set to minm for a min-maximum normalization. All
# amplification curves were smoothed by Savitzky-Golay smoothing.

res.CPP <- cbind(gue[, 1], apply(gue[, -1], 2, function(x) {
  CPP(gue[, 1], x, trans = TRUE, method.norm = "minm", method.reg = "least",
      bg.range = c(1,7))[["y.norm"]]
}))

# Use the th.cyc function from the chipPCR package to calculate the Cq values
# by the cycle threshold method at a threshold signal level "r" of 0.05.
Cq.Ct <- apply(gue[, -1], 2, function(x) 
  th.cyc(res.CPP[, 1], x, r = 0.05)[1])

# Use the inder function from the chipPCR package to calculate the Cq values
# by the SDM method.
Cq.SDM <- apply(gue[, -1], 2, function(x)
  summary(inder(res.CPP[, 1], x), print = FALSE)[2])

# Fit a linear model to carry out a regression analysis.
res.Cq <- lm(Cq.Ct ~ Cq.SDM)
\end{example}

To compare the $Cq_{SDM}$ and $Cq_{Ct}$ methods we performed a regression 
analysis. The Cq methods are in a good agreement. However, the dispersion of 
the 
$Cq_{Ct}$ values appeared to be higher than in the $Cq_{SDM}$ values 
(Figure~~\ref{figure:dilution_Cq}C).

\begin{example}
> summary(res.Cq)

Call:
lm(formula = Cq.Ct ~ Cq.SDM)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.4904 -0.2730  0.0601  0.3540  1.1871 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -8.125534   0.207419  -39.17   <2e-16 ***
Cq.SDM       0.988504   0.008097  122.08   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5281 on 82 degrees of freedom
Multiple R-squared:  0.9945,  Adjusted R-squared:  0.9945 
F-statistic: 1.49e+04 on 1 and 82 DF,  p-value: < 2.2e-16
\end{example}

The dilution (``dil'') and the Cq (``Cq.Ct'') values served as input for the 
calculation of the amplification efficiency ($AE$) with \code{effcalc} function 
from the \CRANpkg{chipPCR} package. In our case study we needed to rearrange 
the 
``Cq.Ct'' values in a matrix using the command $effcalc(dil, t(matrix(Cq.Ct, 
nrow = 12, ncol = 7))$. For visualization of the confidence intervals of the 
regression analysis we set the parameter $CI = TRUE$. Finally, Cq values were 
plotted 
using the \code{layout} function (Figure~\ref{figure:dilution_Cq}D~and~E).

\begin{example}
# Store used margin parameters
def.mar <- par("mar")
layout(matrix(c(1,2,3,3,4,5), 3, 2, byrow = TRUE))
# Set bigger top margin.
par(mar = c(5.1, 4.1, 6.1, 2.1))

matplot(gue[, -1], type = "l", lty = 1, col = 1, xlab = "Cycle", 
	    ylab = "RFU", main = "Raw data")
legend("topleft", "A", cex = 3, bty = "n")

matplot(res.CPP[, -1], type = "l", lty = 1, col = 1, xlab = "Cycle", 
	ylab = "RFU", main = "Pre-processed data")
legend("topleft", "B", cex = 3, bty = "n")
abline(h = 0.05, col = "red", lwd = 2)

plot(Cq.SDM, Cq.Ct, xlab = "Ct method", ylab = "SDM method", 
     main = "Comparison of Cq methods")
abline(res.Cq)
legend("topleft", "C", cex = 3, bty = "n")

plot(effcalc(dil, t(matrix(Cq.Ct, nrow = 12, ncol = 7))), CI = TRUE)
legend("topright", "D", cex = 3, bty = "n")

plot(effcalc(dil, t(matrix(Cq.SDM, nrow = 12, ncol = 7))), CI = TRUE)
legend("topright", "E", cex = 3, bty = "n")

# Restore margins to default values.
par(mar = def.mar)
\end{example}

As shown in this case study, it is easy to set-up a streamlined workflow for 
data 
read-in, pre-processing and analysis with a few functions.

\subsection{Case study two -- qPCR and Melting Curve Analysis}

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14cm]{figures/plotCurves.pdf}
  \caption{Analysis of the amplification curve data. The calibration curve 
samples were inspected by the \code{plotCurves} function from the 
\CRANpkg{chipPCR} package. The green color code indicates that the data contain 
no missing values. However, the visual inspection revealed that the data are 
noisy. All samples (``D1\_Alm12\ldots'' - ``D8\_Alm12\ldots'') appeared to be 
positive. One negative control (``D10\_H20\_ntc\_EvaGreen'') seems to be 
contaminated.}
  \label{figure:plotCurves}
\end{figure}


A common task during the analysis of qPCR experiments is to distinguish between 
positive and negative samples (see Figure~\ref{figure:plotCurves}). If the 
melting temperature of a sample is known it is possible to automatize the 
decision by a melting curve analysis (MCA). As shown in 
\citet{roediger_RJ_2013} 
this can be done by interrogating the $T_{M}$. Therefore, we used a logical 
statement, which tests if $T_{M}$ is within a tight temperature range. We used 
the signal height as second parameter. In line with ``Case study one'' we used 
the function $sessionInfo()$ to track all packages used during the analysis. 
Reproducible research is greatly enhanced if open data exchange formats are 
used. Therefore, we used the \CRANpkg{RDML} package for data read-in. The 
amplification and melting curve data were measured with a CFX96 system 
(Bio-Rad) 
and then exported as RDM~v~1.1 format file as \file{BioRad\_qPCR\_melt.rdml}. 
Within this qPCR experiment we amplified the \textit{Mycobacterium 
tuberculosis} 
\textit{katG}\footnote{\url{https://www.wikigenes.org/e/gene/e/923602.html}} 
gene and tried to detect a mutation at codon 315. The experiment was separated 
in two parts: 
\begin{enumerate}
 \item Detection of overall \textit{M.~tuberculosis} DNA (wild-type 
and mutant) and
 \item specific detection of wild-type \textit{M.~tuberculosis} by melting of 
TaqMan probe (quencher -- BHQ2, fluorescent reporter -- Cy5) with amplified DNA 
(see \citet{luo_multiplex_2011} for probe/primer sequences and further details).
\end{enumerate}


The qPCR was conducted using EvaGreen\circledR~Master Mix (Syntol) according to 
the manufacturer's instructions, with 500 nM of primers and probe in a 25 
$\mu$L 
final reaction volume. Thermocycling was conducted using a CFX96 (BioRad) 
initiated by 3 min incubation at 95~\textcelsius, followed by 41 cycles (15 s 
at 
95~\textcelsius; 40 s at 65~\textcelsius) with a single read-out 
taken at the end of each cycle. Probe melting was conducted between 
35~\textcelsius~and 95~\textcelsius~by 1~\textcelsius~at 1 s steps.

IMPROVEME
The structure of an RDML file is quite complex. Though RDML files are XML 
structured files and thus intended to be readable by humans, it is hard to 
grasp the complex hierarchical file structure with out some basic understanding. 
A simple and fast method to compactly display the structure of object in R is 
to use the \code{str} or \code{summary} function (not shown). However, such R 
tools are not informative in this context. Therefore we implemented a 
dendrogram like view. Only a subset of the data was used in our case study and 
combined to the object ``qPCR''.
IMPROVEME

\begin{example}
# Import the qPCR and melting curve data via the RDML package.
# Load the chipPCR package for the pre-processing and curve data quality
# analysis and the MBmca package for the melting curve analysis.
require(RDML)
require(chipPCR)
require(MBmca)

# Collect information about the R session used for the analysis of the qPCR
# experiment.
current.session <- sessionInfo()

# Load the BioRad_qPCR_melt.rdml file form RDML package and assign the data to 
# the object BioRad.

filename <- paste(path.package("RDML"), "/extdata/", 
		  "BioRad_qPCR_melt.rdml", sep = "")
BioRad <- RDML(filename, name.pattern = "%TUBE%_%NAME%_%TYPE%_%TARGET%")

# Fetch cycle dependent fluorescence for the EvaGreen channel of the 
# katG gene and aggregate the data in the object qPCR.

qPCR <- cbind(BioRad[["qPCR"]][["EvaGreen"]][["pos"]], 
	      BioRad[["qPCR"]][["EvaGreen"]][["unkn"]][, -1], 
	      BioRad[["qPCR"]][["EvaGreen"]][["ntc"]][, -1])
	      
# Leave data only from row 'D' that contains target 'Cy5-2' at channel 'Cy5'
qPCR <- cbind(qPCR[,1], qPCR[, grep("^D", names(qPCR))])
\end{example}

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14cm]{figures/amp_melt.pdf}
  \caption{Graphical representation of the amplification curve data and melting 
curve data. \strong{(A)} The raw amplification curve data were pre-processed 
with the \code{CPP} function prior to visualization. To calculate the $T_{M}$ 
values from the raw melting curve data \strong{(B)} we used the \code{diffQ} 
function from the \CRANpkg{MBmca} package. \strong{(C)} We adjusted our 
algorithm to plot the true positive melting peaks in red, while negative 
melting 
peaks were labelled in black.} 
\label{figure:amp_melt}
\end{figure}

We inspected and pre-processed a subset of the amplification curve data solely 
using functionalities provided by the \CRANpkg{chipPCR} package. The 
\code{plotCurves} function was used to get an overview of the curvatures. The 
data indicated a baseline shift in all curves with a slight negative trend 
(Figure~\ref{figure:plotCurves}). This observation suggested to baseline the 
raw data by 
using a linear regression model (cycles x - y; ($bg.range = c(x, y)$) in the 
\code{CPP} function.).

\begin{example}
# Use plotCurves function to get an overview of the amplification curve samples.

plotCurves(qPCR[, 1], qPCR[, -1], type = "l")

# Detect positive samples - calculate Cq values by the cycle threshold method. 
# The threshold signal level r was set to 10.
Cq.Positive <- t(apply(qPCR[, -1], 2, function(x)
{
  res <- CPP(qPCR[, 1], x, trans = TRUE, bg.range = c(2, 8),
             method.reg = "least")[["y.norm"]]
  # The th.cyc fails when the threshold exceeds maximum 
  # observed fluorescence values, so it must be used with try()
  th.cycle <- try(th.cyc(qPCR[, 1], res, r = 10)[1], silent = TRUE)
  cq <- ifelse(class(th.cycle) != "try-error", as.numeric(th.cycle), NA)
  pos <- !is.na(cq)
  c(Cq=cq, M.Tub_positive = pos)
}
))
Cq.Positive
\end{example}

Since the amplification curves indicated that selected samples (except 
non-template-control (``NTC'')) are positive, we distinguished between true 
positive and true negative samples by MCA (Figure~\ref{figure:amp_melt}A).

\begin{example}
# Fetch temperature dependent fluorescence for the Cy5 channel of the 
# probe that can hybridize with Mycobacterium tuberculosis katG gene (codon 315)
# and aggregate the data in the object 'melt'.
melt <- cbind(BioRad[["Melt"]][["Cy5-2"]][["pos"]],
              BioRad[["Melt"]][["Cy5-2"]][["unkn"]][, -1],
              BioRad[["Melt"]][["Cy5-2"]][["ntc"]][, -1])

# Calculate the melting temperature with the diffQ function from the MBmca 
# package. Use simple logical conditions to find out if a positive sample with 
# the expected Tm of circa 54.5 degree Celsius is found. The result of the test
# is assigned to the object 'positive'.
Tm.Positive <- matrix(nrow = length(melt[, -1]),
                      byrow = TRUE,
                      dimnames = list(names(melt)[-1]),
                      unlist(apply(melt[, -1], 2, function(x) {
                        res.Tm <- diffQ(cbind(melt[, 1], x), 
					fct = max, inder = TRUE)
                        positive <- ifelse(res.Tm[1] > 54 & 
                                             res.Tm[1] < 55 & 
                                             res.Tm[2] > 80, 1, 0)
                        c(res.Tm[1], res.Tm[2], positive)
                      })))

# Present the results in a tabular output as data.frame 'results.tab'.
# Result of analysis logic is:
# Cq.Positive && Tm.Positive = Wild-type
# Cq.Positive && !Tm.Positive = Mutant
# !Cq.Positive && !Tm.Positive = NTC
# !Cq.Positive && Tm.Positive = Error
results <- sapply(1:length(Cq.Positive[, 1]), function(i) {
  if(Cq.Positive[i, 2] == 1 && Tm.Positive[i, 3] == 1)
    return("Wild-type")
  if(Cq.Positive[i, 2] == 1 && Tm.Positive[i, 3] == 0)
    return("Mutant")
  if(Cq.Positive[i, 2] == 0 && Tm.Positive[i, 3] == 0)
    return("NTC")
  if(Cq.Positive[i, 2] == 0 && Tm.Positive[i, 3] == 1)
    return("Error")
})

results.tab <- data.frame(cbind(Cq.Positive, Tm.Positive, results))
names(results.tab) <- c("Cq", "M.Tub DNA", "Tm", "Height", 
                        "Tm positive", "Result")

results.tab[["M.Tub DNA"]] <- factor(results.tab[["M.Tub DNA"]], 
                                     labels=c("Not Detected", "Detected"))

results.tab[["Tm positive"]] <- factor(results.tab[["Tm positive"]], 
                                       labels=c(TRUE, FALSE))
results.tab
\end{example}

The results of the analysis can be invoked by the statement $results.tab$ (not 
shown). Finally, we plotted and printed the output of our melting curve 
(Figure~\ref{figure:amp_melt}B) and melting peak 
(Figure~\ref{figure:amp_melt}C) 
analysis.

\begin{example}
# Convert the decision from the results.tab object in a color code:
# Negative, black; Positive, red.

color <- c(Tm.Positive[, 3] + 1)

# Arrange the results of the calculations in plot.
layout(matrix(c(1,2,1,3), 2, 2, byrow = TRUE))

# Use the CPP function to preporcess the amplification curve data.
plot(NA, NA, xlim = c(1, 41), ylim = c(0,200), xlab = "Cycle", ylab = "RFU")
mtext("A", cex = 2, side = 3, adj = 0, font = 2)
lapply(2L:ncol(qPCR), function(i) 
  lines(qPCR[, 1], 
        CPP(qPCR[, 1], qPCR[, i], trans = TRUE, 
            bg.range = c(1,9))[["y.norm"]],
        col = color[i - 1]))

matplot(melt[, 1], melt[, -1], type = "l", col = color, 
        lty = 1, xlab = "Temperature [degree Celsius]", ylab = "RFU")
mtext("B", cex = 2, side = 3, adj = 0, font = 2)

plot(NA, NA, xlim = c(35, 95), ylim = c(-15, 120), xlab = "Temperature [degree 
Celsius]", 
     ylab = "-d(RFU)/dT")
mtext("C", cex = 2, side = 3, adj = 0, font = 2)

lapply(2L:ncol(melt), function(i)
  lines(diffQ(cbind(melt[, 1], melt[, i]), verbose = TRUE, 
              fct = max, inder = TRUE)[["xy"]], col = color[i - 1]))
\end{example}

\subsection{Case study three -- Isothermal Amplification}
Isothermal amplification is an alternative to PCR, which uses a constant 
temperature rather than cycling through denaturation, annealing and extension 
steps \citep{rodiger_nucleic_2014}. The corresponding signal is monitored 
continuously on a time basis. Often the abscissa values are not uniformly 
spaced\footnote{The \texttt{C81} example data sets chosen in this case study 
are 
not uniformly spaced. The \code{CPP} function gives a warning in such a case.}. 
In qIA the $Cq$ values are dependent on the time instead of cycles. In this 
study we used the \code{th.cyc} function to determine the time ($Cq_{t}$) 
required to reach a certain threshold signal level.

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14cm]{figures/qIA.pdf}
  \caption{Quantitative isothermal amplification by Helicase Dependent 
Amplification (HDA). \strong{(A)} The raw data of the HDA (D1, undiluted, D2 
$1:10$ diluted) exhibit some outliers (detector artifacts), an off-set of circa 
0.5 relative fluorescence units (RFU) and a slight negative trend in the 
baseline region (0~-~52 minutes). \strong{(B)} First we used the \code{CPP} 
function to smooth the data with a spline function. Baselining was done with a 
linear regression model (robust MM-estimator). Finally, we used the 
\code{th.cyc} function (\CRANpkg{chipPCR}) to calculate the cycle threshold 
time for samples D1 and 
D2. The threshold value was set to $r = 0.05$ ($--$, threshold line).}
  \label{figure:qIA}
\end{figure}
We performed a quantitative isothermal amplification (qIA) with the plasmid 
\textit{pCNG1} by using a Helicase Dependent Amplification (HDA). Our 
previously 
reported VideoScan platform \citep{rodiger_highly_2013} was used to control the 
temperature and to monitor the amplification reaction. The VideoScan technology 
is based 
on a highly versatile fluorescence microscope imaging platform, which can be 
operated with a heating/cooling unit (HCU) for qPCR and MCA applications 
\citep{roediger_RJ_2013, rodiger_highly_2013}. Since the enzyme DNA Helicase 
unwinds DNA, no thermal denaturation is needed. The HDA conditions were taken 
from the ``IsoAmp III Universal tHDA Kit'', Biohelix Corp, as described by the 
vendor. In detail, the reaction was composed of ``mix A'' 10 $\mu$L A. bidest, 
1.25 $\mu$L 10x~buffer, 0.75 $\mu$L primer (150 nM final), 0.5 $\mu$L template 
plasmid. Preincubation: The mixture was incubated for 2 min at 
95\textcelsius~and immediately placed on ice. Reaction ``mix B'' contained 5 
$\mu$L A. bidest., 1.25 $\mu$L 10x buffer, 2 $\mu$L NaCl, 1.25 $\mu$L 
$MgSO_{4}$, 1.75 $\mu$L dNTPs, 0.25 $\mu$L EvaGreen (Biotium), 1 $\mu$L enzyme 
mix. The mix was covered with 50 $\mu$L mineral oil (Roth). The fluorescence 
measurement in VideoScan HCU started directly after adding ``mix B'' at 
65\textcelsius. A $1x$ (D1) and a $1:10$ dilution (D2) were tested. The 
resulting dataset \texttt{C81} is part of the \CRANpkg{chipPCR} package. Two 
concentrations (stock and 1:10 diluted stock) of input DNA were used in the 
HDA. 
Similar to the previous case studies, we first prepared the plot of the data. 
Since the raw data showed a slight negative trend and an off-set of circa 0.45 
RFU it was necessary to pre-process the raw data (Figure~\ref{figure:qIA}A).

\begin{example}
# Drawn in an 2-by-1 array on the device by two columns and one row.
par(mfrow = c(2, 1))

# Plot the raw data from the C81 dataset to the first array and add
# a legend. Note: The abscissa values (time in seconds) was divided 
# by 60 (C81[, i] / 60) to convert to minutes.
plot(NA, NA, xlim = c(0, 120), ylim = c(0, 1.2), xlab = "Time (min)", ylab = 
"RFU")
mtext("A", cex = 2, side = 3, adj = 0, font = 2)
lapply(c(2, 4), function(i) {
  lines(C81[, i] / 60, C81[, i + 1], type = "b", pch = 20, col = i - 1)
})
legend(10, 0.8, c("D1: 1x", "D2: 1:10 diluted sample"), pch = 19, col = c(1, 
3), 
       bty = "n")

# Prepare a plot on the second array for the pre-processed data.
plot(NA, NA, xlim = c(0, 120), ylim = c(0, 1.2), xlab = "Time (min)", ylab = 
"RFU")
mtext("B", cex = 2, side = 3, adj = 0, font = 2)
\end{example}

First, we used the \code{CPP} function to pre-process the raw data. Similar to 
the other case studies we baselined and smoothed the amplification curve data 
prior to the analysis of the of the $Cq_{t}$ value. However, instead of the 
Savitzky-Golay smoother we used a cubic spline ($method = "spline"$) in the 
\code{CPP} function. In addition, outliers were automatically removed in the 
baseline region (Figure~\ref{figure:qIA}A~and~B). The background range was 
defined to be between the $1^{th}$ and $190^{th}$ data point (corresponds to 
baseline region between 0~and~52 minutes).

\begin{example}
  # Apply the CPP functions to pro-process the raw data.1) Baseline data to 
zero, 
  # 2) Smooth data with a spline, 3) Remove outliers in background range 
between 
  # entry 1 and 190. Assign the results of the analysis to the object 'res'.
res <- lapply(c(2, 4), function(i) {
  y.s <- CPP(C81[, i] / 60, C81[, i + 1],
             trans = TRUE, 
             method = "spline",
             bg.outliers = TRUE,
             bg.range = c(1, 190))
  lines(C81[, i] / 60, y.s[["y.norm"]], type = "b", pch = 20, col = i - 1)
  # Use the th.cyc function to calculate the cycle threshold time (Cq.t). 
  # The threshold signal level r was set to 0.05.
  paste(round(th.cyc(C81[, i] / 60, y.s[["y.norm"]], r = 0.05)[1], 2), "min")
})

# Add the cycle threshold time from the object 'res' to the plot.

abline(h = 0.05, lty = 2)
text(10, 0.55, "Cq.t:")
legend(10, 0.5, paste(c("D1: ", "D2: "), res), pch = 19, col = c(1, 3), 
       bty = "n")
\end{example}

The pre-processed data were subjected to the analysis of the $Cq_{t}$ values. 
It is important to note that the trend correction and proper baseline was a 
requirement for a sound calculation. We calculated $Cq_{t}$ values of 
70.18~minutes and 93.18 minutes for the stock (D1) and 1:10 (D2) diluted 
samples, receptively.

\subsection{Case study four - digital PCR}

We have developed the \CRANpkg{dpcR} package for analysis and presentation of 
digital PCR experiments. The \CRANpkg{dpcR} package can be used to build 
custom-made analysers and provides structures to be openly extended by the 
scientific community. Simulations and predictions of binomial and Poisson 
distributions, commonly used theoretical models of dPCR, statistical data 
analysis methods, plotting facilities and report generation tools are part of 
the package \citep{pabinger_2014}. Here, we show a case study for the 
\CRANpkg{dpcR}. Simulations are part in many educational curricula and support 
teaching greatly. In this case study, we mimicked an in-silico experiment for a 
droplet digital PCR similar to Figure~\ref{figure:dpcR_sim}. The aim was to 
assess the concentration of the template sample. The number of positive 
partitions ($k$), total number of partitions ($n$) and the size of the 
partition 
are only data required for the analysis. The estimate of the mean number of 
template molecules per partition ($\hat \lambda$) was calculated using 
following 
equation \citep{huggett_2013}:

\begin{equation}
\hat{\lambda} =  -\ln{(1 - \frac{k}{n})}.
\end{equation}

The average droplet volume in our experiment was assumed to be 5 nL. We counted 
$n = 16800$ droplets in total from which $k = 4601$ droplets were positive. The 
binomial distribution of positive and negative partitions was used to determine 
$\hat \lambda$. R allows both easy estimation of a density of the parameter and 
calculation of confidence intervals using Wilson method \citep{brown_2001}. The 
obtained mean number of template molecules per partition multiplied by the 
volume of the partitions ($ 16800 * 5~nL$) constitutes the sample concentration.

\begin{example}
# Load the dpcR package for the analysis of the digital PCR experiment.
require(dpcR)

# Analysis of a digital PCR experiment. The density estimation.
# In our in-silico experiment we counted in total 16800 droplets (n). 
# Thereof, 4601 were positive (k).

(dens <- dpcr_density(k = 4601, n = 16800, average = TRUE, methods = "wilson"))

# Let us assume, that every droplet has roughly a volume of 5 nL.
# The total concentration (and its confidence intervals) in molecules/ml is:
dens[4:6] / 5 * 1e-6
\end{example}

Selected functionality was implemented as interactive \CRANpkg{shiny} GUI 
application to make the software accessible for users who are not fluent in R 
and for experts who wish to automatize routine tasks. Details and examples of 
the \CRANpkg{shiny} web application framework for R can be found at 
\url{http://shiny.rstudio.com/}. We implemented 
flexible user interfaces, which run the analyses and graphical representation 
into interactive web applications either as service on a web severer or on a 
local machine without knowledge of HTML or ECMAScript (see \CRANpkg{dpcR} 
manual). The interface is designed in a cascade workflow approach (Data import 
$\rightarrow$ Analysis $\rightarrow$ Output $\rightarrow$ Export) with 
interactive users choice on input data, methods and parameters using typical 
GUI 
elements such as sliders, drop-downs and text fields. An example can be found 
at 
\url{https://michbur.shinyapps.io/dpcr_density/}. This approach enables the 
automatized outputs of R objects in combined plots, tables and summaries.

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=7cm]{figures/dpcR.pdf}
  \caption{\code{dpcr\_density} function from the \CRANpkg{dpcR} package used 
for analysis of droplet digital PCR experiment. From 16800 counted droplets 
($n$) 4601 were positive ($k$). The chart presents the distribution of mean 
number of 
template molecules per partition ($\hat \lambda$). 
}
  \label{figure:dpcR}
\end{figure}

\subsection{Case study five - digital PCR correction}

Case study four gave an introduction for the analysis of dPCR experiments with 
the \CRANpkg{dpcR} package. In this case study we used the \CRANpkg{dpcR} to 
analyse real-world dPCR data from a Bio-Rad QX100 experiment. There is an 
ongoing debate in the scientific community about the effect of the partition 
volume on the estimated copy numbers size \citep{huggett_clinchem_2014, 
corbisier_2015}. \citet{corbisier_2015} showed that the partition volume is a 
critical parameter for the measurement of copy number concentrations. Moreover, 
their study revealed that the average droplet volume is 8~\% lower than the 
volume defined in the QuantaSoft software (v.~1.3.2.0, Bio-Rad). In consequence, 
all quantifications were systematically biased. In this case study we use the 
\texttt{pds\_raw} data set from the \CRANpkg{dpcR} package and re-analysed the 
data with the partition volume of 0.834~nL as proposed by 
\citet{corbisier_2015}.

\begin{example}
require(dpcR)
# Load the dpcR package for the analysis of the digital PCR experiment.
# Analysis of a droplet dPCR experiment. Data were taken from the pds_raw dataset.

# Select the wells for the analysis.

wells <- c("A01", "B01", "C01", "D01", "G04")

# Set the arrangement for the plots.
par(mfrow = c(5,3))

for (i in 1L:length(wells)) {
  cluster.info <- unique(pds_raw[wells[i]][[1]]["Cluster"])
  res <- bioamp(data = pds_raw[wells[i]][[1]], amp_x = 2, amp_y = 1, 
		main = paste("Well", wells[i]), xlab = "Amplitude of ileS (FAM)",
		ylab = "Amplitude of styA (HEX)", xlim = c(500,5500), 
		ylim = c(0,3000), pch = 19)
  legend("topleft", as.character(cluster.info[, 1]), col = cluster.info[, 1], 
	 ncol = 4, pch = 19)
  
  dens <- dpcr_density(k = res[1, "Cluster.3"], n = sum(res[1, ]), 
			average = TRUE, methods = "wilson")  
  res.conc <- rbind(original = dens[4:6] /  0.90072 * 1e-6, 
		    corrected = dens[4:6] / 0.834 * 1e-6)
  barplot(res.conc[, 1], col = c("white","grey"), 
	  names = c("Bio-Rad", "Corbisier"), 
	  main = "Droplet size", ylab = "molecules/ml", ylim = c(0,8*10E-9))
    arrows(c(0.7,1.9), res.conc[, 2], c(0.7,1.9), res.conc[, 3], angle = 90, 
	   code = 3, lwd = 2)
}
\end{example}

\begin{figure}[htbp]
\centering
  \includegraphics[clip=true, width=14cm]{figures/dpcR_bioamp.pdf}
    \caption{Analysis of a droplet digital PCR experiment. We used the 
\texttt{pds\_raw} data set from the \CRANpkg{dpcR} package. 
    }  \label{figure:dpcR_bioamp}
\end{figure}

\section{Discussion and Conclusion}

This study gave a brief introduction to the analysis of qPCR, qIA, MCA and dPCR 
experiments with R. In addition to this, we briefly referenced to a vast 
collection of 
additional packages available from CRAN and Bioconductor. The packages may be 
considered as the building blocks (libraries) to create what users want and 
need. We 
showed that automatized research with R offers powerful means for statistical 
analysis and visualization. The software is not tied to a vendor or specific 
application (e.g., chamber or droplet based digital PCR, capillary or plate 
qPCR). It should be quite easy even for an inexperienced user to define a 
workflow and to set up an environment for specific needs in a broad range of 
technical settings (Figure~\ref{figure:options}). R enforces no monolithic 
integration. We claim that the modular structure of R packages allows the user 
to 
perform flexible data analysis, adjusted to their needs and to design 
frameworks 
for high-throughput analysis. Furthermore, R enables the user to access and 
reuse code for the creation 
of reports in various formats (e.g., HTML, PDF). Most of the software is 
cross-platform open source software. Despite the fact that R is free of charge, 
it is quite possible to build commercial applications. The packages cover 
implementation of novel approaches and peer-reviewed analysis methods. R 
packages are an open environment to adopt to the growing knowledge in life 
sciences and medical sciences. Therefore, we argue that R may provide a 
structure for standardized nomenclature and serve as reference in qPCR and dPCR 
analysis. Speaking about openness, it needs to be emphasized that the main 
advantage of this software is its transparency at any time for anybody. Thus, 
it is 
possible to track numerical errors.  A serve disadvantage of R is the lack of 
comprehensive GUIs for qPCR analysis. Others and we believe that a graphical 
user 
interface (GUI) is a key technology to spread the use of R in bioanalytical 
sciences. Currently, we are establishing the ``pcRuniveRsum'' 
(\url{http://michbur.github.io/pcRuniveRsum/}) as an on-line resource for the
interested users. The command-line structure makes R ``inaccessible'' for many 
novices. We try to solve this problem with easily accessible 
GUIs \citep{rodiger_rkward_2012}. However, the work on this additions has been 
recently started and is still in progress.

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=10cm]{figures/options.png}
  \caption{Deployment of R applications for the qPCR and dPCR experiments. 
\strong{(A)} R is typically run from a desktop computer an operated by an 
GUI/IDE application such as \pkg{Rstudio} or \pkg{RKWard}. This approach 
provides a flexible workflow for individuals. \strong{(B)} Another approach is 
to run R with specific applications on a local server. Such scenarios are 
useful 
for the deployment within research departments or cooperate units 
\citep{R_web}. 
\strong{(C)} Cloud computing (CC) provides shared and scalable computing 
capacity (e.g., computing capacity, application software) and storage capacity 
(e.g., databases) as a service to an individual user or a community Service 
categories include: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service 
(PaaS) and Software-as-a-Service (SaaS) over a network. Providers of CC manage 
the infrastructure and resources to achieve coherence and economies of scale 
similar to a utility over a network (i.~p., Internet) \citep{R_cloud}.}
  \label{figure:options}
\end{figure} 

\section{Acknowledgment}

Part of this work was funded by the BMBF InnoProfile-Transfer-Projekt 03 IPT 
611X. We would like to thank the R community. Part of this work was funded by 
the 
Russian Ministry of Education and Science (project No. RFMEFI62114X0003) and 
with usage of scientific equipment of Center for collective use 
``Biotechnology'' at All-Russia Research Institute of Agricultural 
Biotechnology. We would like to thank Mario Menschikowski (Technical University 
Dresden) for the droplet digital PCR samples.

\bibliography{roediger-burdukiewicz-blagodatskikh-schierack}

\address{Stefan R\"odiger (corresponding author)\\
  Faculty of Natural Sciences\\
  Brandenburg University of Technology Cottbus--Senftenberg\\
  Senftenberg\\
  Germany}
\email{Stefan.Roediger@b-tu.de}

\address{Micha\l{} Burdukiewicz\\
  University of Wroclaw\\
  Faculty of Biotechnoloy\\
  Department of Genomics\\
  Wroclaw\\
  Poland}
\email{michalburdukiewicz@gmail.com}

\address{Konstantin Blagodatskikh\\
  All-Russia Research Institute of Agricultural Biotechnology\\
  Center for collective use ``Biotechnology''\\
  Moscow\\
  Russia}
\email{k.blag@yandex.ru}

\address{Peter Schierack\\
  Faculty of Natural Sciences\\
  Brandenburg University of Technology Cottbus--Senftenberg\\
  Senftenberg\\
  Germany}
\email{Peter.Schierack@hs-lausitz.de}
