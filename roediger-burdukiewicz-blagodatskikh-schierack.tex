% !TeX root = RJwrapper.tex
\title{R as an Environment for the Analysis of dPCR and qPCR Experiments}
\author{by Stefan R\"{o}diger, Micha\l{} Burdukiewicz, Konstantin 
Blagodatskikh, Michael Jahn and Peter Schierack}

\maketitle

\abstract{
There is an ever-increasing number of applications, which use quantitative PCR 
(qPCR) or digital PCR (dPCR) to elicit fundamentals of biological processes. 
Moreover, the novel amplification strategies based on quantitative isothermal 
amplification (qIA) have become more prominent in life sciences and 
point-of-care-diagnostics. Additionally, the analysis of melting data is 
essential during many experiments. Several software packages have been developed 
for the analysis of such datasets. In most cases, the software is either 
distributed as closed source software or as monolithic block with little freedom 
to perform highly customized analysis procedures. We argue, among others, that R is 
an excellent foundation for reproducible and transparent data analysis in a 
highly customizable cross-platform environment. However, for novices it is often 
challenging to master R or learn capabilities of the vast number of packages 
available. In the paper, we describe exemplary workflows for the analysis of 
qPCR, qIA or dPCR experiments including the analysis of melting curve data. Our 
analysis relies entirely on R packages available from public repositories. 
Additionally, we provide information related to standardized and reproducible 
research with R.
}

\section{Introduction}

The quantitative Polymerase Chain Reaction (qPCR) is the method of choice when 
a precise quantification of minute DNA traces is required. The applications 
include the detection and quantification of pathogens or gene expression 
analysis \citep{pabinger_2014}. Only few bioanalytical methods had such a 
significant impact on the progress of life sciences and medical sciences as the 
qPCR \citep{huggett_qpcr_2015}. Numerous commercial and experimental monitoring 
platforms have been developed in the past years. This includes standard plate 
cyclers, capillary cyclers, microfluidic platforms and related technologies 
\citep{rodiger_highly_2013, viturro_2014, rodiger_nucleic_2014, khodakov_2014, 
wu_2014}.

In the past decades several isothermal amplification technologies emerged, such 
as helicase dependent amplification (HDA), as alternative to PCR. The isothermal 
amplification was readily combined with real-time monitoring technologies (qIA) 
or digital PCR and is used in various fields like diagnostics and 
point-of-care-testing \citep{selck_2013, rodiger_nucleic_2014, nixon_2014}.

The digital PCR (dPCR) is a novel approach for detection and quantification of 
nucleic acids and can be seen as a next generation method 
\citep{huggett_qpcr_2015}. The dPCR technology breaks fundamentally with the 
previous concept of nucleic acid quantification. The key difference between dPCR 
and traditional qPCR lies in the method of measuring (absolute) nucleic acids 
amounts, which yields discrete information instead of the continuous signal. 
This is possible after ``clonal DNA amplification'' in thousands of small 
separated partitions (e.g., droplets, nano chambers) \citep{huggett_2013, 
milbury_2014, morley_2014}. The partitions with no nucleic acid remain negative 
and the others turn positive (e.g., Figure~\ref{figure:dpcR_sim}). Selected 
technologies (e.g., OpenArray\textregistered Real-Time PCR System) monitor 
amplification reactions in the chambers (``partitions'') in real-time. After 
that, all quantification cycle (Cq) values are calculated from the amplification 
curves and converted into discrete events by means of positive and negative 
chambers. Finally, the absolute quantification of nucleic acids is done using 
Poisson statistics. Recently, we have published the \CRANpkg{dpcR} package at 
CRAN, which is the first open source R software package for the analysis of dPCR 
experiments (see \CRANpkg{dpcR} for details).

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=12cm]{figures/dpcR_sim.pdf} \caption{Scheme 
of a digital PCR experiment. \strong{(A)} A droplet digital PCR reaction 
mix was formed in a BioRad QX100 Droplet Digital PCR System. The droplets (circa 
100 $\mu$m in diameter) were subjected to custom made slide chambers for the 
detection and analysis in fully automatized imaging VideoScan platform 
\citep{rodiger_highly_2013}. \strong{(B)} Subsequently the samples can be 
digitalized by counting number of positive and total number of droplets. The 
plot was generated with the \code{sim\_ddpcr} function from the \CRANpkg{dpcR} 
package.}
\label{figure:dpcR_sim}
\end{figure}

Many of the commercial and experimental hardware platforms provide means to 
analyse the data. The complexity of hardware, wetware and software requires 
expertise to master a workflow. This comprises standards for experiment design, 
generation and analysis of data, multiple hypothesis testing, interpretation, 
reporting and storage of results \citep{huggett_BDQ_2014, conde_2014}. 
Scientific misconduct and fraud have shaken the scientific community on several 
occasions \citep{bustin_2014}. In particular, the scientific community works 
hard to uncover pitfalls of qPCR experiments. This lead to the development of 
peer-reviewed quantification cycle (Cq) analysis algorithms 
\citep{ruijter_2013}, fully characterized qPCR chemistries 
\citep{ruijter_2014} and guidelines for a proper conduct of qPCR experiments as 
implemented in the MIQE guidelines (minimum information for publication of 
quantitative real-time PCR experiments) \citep{huggett_2013, bustin_2014}. We 
share the philosophy of the MIQE guidelines to increase the experimental 
transparency for better experimental practice and reliable interpretation of 
results and encourage the use of open data exchange formats like the XML-based 
Real-Time PCR Data Markup Language (RDML) \citep{lefever_2009}. We see the 
application of R in line with this philosophy. 

In case of closed source software the analysis usually happens in a black~box 
fashion tied to a specific platform. We agree that closed frameworks are 
not necessarily a bad thing, but should be avoided if possible 
\citep{roediger_RJ_2013, Spiess_2014}. Studies by \citet{mccullough_2008, 
Almiron_2010, Duran_2014} exemplified where the black~box approach might fail in 
science. The same holds true for the open~source software since software bugs 
are independent of a development model. However, at least open~source gives the 
possibility to track and eliminate errors by an individual entity. 

Black-box systems often force the user to process the data by suboptimal 
analysis algorithms \citep{ruijter_2013}. Moreover, the data usually cannot be 
accessed between the steps of the analysis which restrains quality control. The 
visualization options are usually limited by the software vendor preferences and 
do not attain publication quality. In addition to this, users who have no access 
to the commercial software are barred. 

Aside from closed source software, data analysis is often performed in 
spreadsheets. However, this data processing approach is not advisable for 
research purposes. Most spreadsheets  lack (or do not use) tools to validate the 
input, to debug implemented procedures and to automatize the workflow. These 
traits make them prone to errors and not well suited for complicated tasks 
\citep{mccullough_2008, burns_2014}.

For several reasons, R is one of the most popular tools in bioinformatics and is 
known as an early adopter of emerging technologies \citep{pabinger_2014}. R 
provides packages to build highly customized workflows, covering: data read-in, 
data preprocessing, analysis, post-processing, visualization and storage. As 
recently briefly reviewed in \citet{pabinger_2014}, numerous R packages have 
been developed for the analysis of qPCR, dPCR, qIA and melting curve analysis 
experiments, including: \CRANpkg{kulife}, \CRANpkg{MCMC.qpcr}, 
\CRANpkg{qPCR.CT}, \CRANpkg{DivMelt}, \CRANpkg{qpcR}, \CRANpkg{dpcR}, 
\CRANpkg{chipPCR}, \CRANpkg{MBmca}, \CRANpkg{RDML}, \BIOpkg{nondetects}, 
\BIOpkg{qpcrNorm}, \BIOpkg{HTqPCR}, \BIOpkg{SLqPCR}, \BIOpkg{ddCt}, 
\BIOpkg{EasyqpcR}, \BIOpkg{unifiedWMWqPCR}, \BIOpkg{ReadqPCR}, 
\BIOpkg{NormqPCR}. All the packages are either available from CRAN or 
Bioconductor \citep{gentleman_2004}. The packages can be freely combined in a 
plugin-like architecture.

R is an open, operating system-independent platform for a broad spectrum of 
calculation options. Particularly, the visualization of experiments is one of 
R's pinnacles. R enables the users to create an efficient manipulation, 
restructuring and reshaping of data to make them readily-available for further 
processing. This is of the particular importance to the human--machine interface 
\citep{Oh_2014}. Intrinsic properties of R such as the naming convention 
\citep{Baaaath_2012} and class systems (e.g., \strong{S3}, \strong{S4}, 
reference classes and \strong{R6}) vary considerable, depending on the package 
developer preferences. However, due to the open source approach, there is the 
common ground to track numerical errors. R offers various methods for a 
standardized data import/export and exchange. Workflows can embed structured 
models \citet{Guazzelli_2009}, open data exchange formats (e.g., RDML), binary 
formats \citep{michna_2013} or tools provided by the R workspace 
\citep{RDCT2010c}. The NetCDF binary format has advantages over some other 
binary formats (e.g., the RData format), since arbitrary array data sections of 
massive datasets can be processed efficiently \citep{michna_2013}. This might be 
useful for large data sets as present in high-throughput PCRs or dPCRs with 
large partition numbers. The R environment offers several datasets, which can be 
used for testing of algorithms. Therefore, others and we argue that R is 
suitable for reproducible research \citep{Murrell_2012, gandrud_2013, 
hofmann_2013, kuhn_cran_2014, Leeper_2014, liu_2014}.

The aim of this paper is to show case studies for qPCR, dPCR, qIA and melting 
curve analysis experiments. Our workflow effectively follows the principle 
illustrated in Figure~\ref{figure:workflow}. We intend to aggregate 
functionalities dispersed between various packages and offer a fast insight in 
the analysis of nucleic acid experiments with R. In particular, we describe how 
to:

\begin{itemize}
 \item read-in data from a standardized file format,
 \item pre-process the amplification curve data,
 \item calculate specific parameters from the amplification curve data,
 \item calculate the melting temperature,
 \item and report the data.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics{figures/workflow.png}
  \caption{Exemplary workflow for quantitative PCR, digital PCR, quantitative 
isothermal amplification and melting curve analysis experiments in R. Core 
functionality is provided by the R software environment for statistical 
computing and graphics. In our scenario we used the \CRANpkg{RDML} package to 
read-in data in standardized format. However, any format supported by R can be 
used. Further, processing of amplification curve data was performed with the 
\CRANpkg{chipPCR} package and melting curve data were analysed with the 
\CRANpkg{MBmca} package. The \CRANpkg{dpcR} package can be embedded in the 
analysis of digital PCR experiments. Cq, quantification cycle; $T_{M}$, melting 
temperature. 
} 
\label{figure:workflow}
\end{figure}

\section{Setting-up a working environment}

We recommend performing the scripting in a dedicated integrated development 
environment (IDE) and graphical user interface (GUI) such as \pkg{RKWard} 
\citep{rodiger_rkward_2012}, \pkg{RStudio} \citep{RStudio, gandrud_2013} or 
other technologies \citep{Valero_2012}. Benefits of IDE's with GUI include 
syntax-highlighting, auto completion and function references for rapid 
prototyping of workflows.

Typically, the analysis will start with data from a commercial platform. Most 
platforms have an option to export a CSV file or spreadsheets application file 
(e.g., *.xls, *.odt). The details for the data import have been described 
elsewhere \citep{RDCT2010c, rodiger_rkward_2012}. To keep the case study 
sections compact we have chosen to load datasets from the \CRANpkg{qpcR} package 
\citep{ritz_2008} (v.~1.4.0) and the \CRANpkg{RDML} package 
(v.~0.8-3) to our workspace. The \CRANpkg{chipPCR} package 
\citep{roediger_2015_Bioinformatics} (v.~0.0.8-8) was used for data 
preprocessing, quality control and  the calculation of the quantification cycle 
(Cq). The Cq is a quantitative measure, which represents the number of cycles 
needed to reach a user defined threshold signal level, in the exponential phase 
of a qPCR/qIA reaction. Several Cq methods have been described 
\citep{ruijter_2013}. In this study we have chosen the second derivative maximum 
method ($Cq_{SDM}$) and the ``Cycle threshold'' ($Cq_{Ct}$) method.

During a perfect qPCR reaction, the target DNA doubles ($2^{n}$; n = cycle 
number) at each cycle. Here the amplification efficiency ($AE$) is 100~\%. 
However, in reality, numerous factors cause an inhibition of the amplification 
($AE$ < 100~\%). The $AE$ can be determined by the relation of the Cq value 
depending on the sample input quantity as described in 
\citep{roediger_2015_Bioinformatics, svec_2015}.

In \citet{roediger_RJ_2013} we described the application of R for the analysis 
of melting curve experiments from microbead-based assays. Since the mathematical 
foundation for melting curve analysis (MCA) is identical between all methods
we used functions from the \CRANpkg{MBmca} package (0.0.3-4) for an 
analysis of the target specific melting temperature ($T_{M}$) in experiments of 
the present study.

We completed our examples with case studies for the analysis of dPCR 
experiments. In particular, we used the \CRANpkg{dpcR} package (0.1.4.0) to 
estimate the number of molecules in a sample.

\section{Results}

In the following sections we will show how R can be used (I) as a unified open 
software for data analysis and presentation in research, (II) as software 
frame-work for novel technical developments, (III) as platform for teaching of 
new technologies and (IV) as reference for statistical methods.

\subsection{Case study one -- qPCR and Amplification Efficiency Calculation}

The goal of our fist case study was to calculate the Cq values and the $AE$ from 
a qPCR experiment. We used the ``guescini1'' dataset from the \CRANpkg{qpcR} 
package, where the gene \textit{NADH dehydrogenase 1} (MT-ND1) was amplified in 
a LightCycler\circledR~480 (Roche) thermocycler. Details of the experiment are 
described in \citet{guescini_2008}. First we started with loading the required 
packages and datasets. A good practice for reproducible research is to track the 
package versions and environment used during the analysis. The function 
\code{sessionInfo} from the \CRANpkg{utils} package provides this information. 
Assuming that the analysis starts with a clean R session it is possible to 
assign the required packages to an object, as shown below. The reproducibility 
of research can be further improved by the \CRANpkg{archivist} package, which 
stores and recovers crucial data and preserves metadata of saved objects (not 
shown). All settings of R session can be easily saved and/or restored using 
\CRANpkg{settings} package.

\begin{example}
# Load the required packages for the data import and analysis.
# Load the chipPCR package for the pre-processing and curve data quality
# analysis and load the qpcR package as data resource.
require(chipPCR)
require(qpcR)

# Collect information about the R session used for the analysis of the
# experiment.
current.session <- sessionInfo()

# Next load the 'guescini1' dataset from the qpcR package to the
# workspace and assign it to the object 'gue'.
gue <- guescini1

# Define the dilution of the sample DNA quantity for the calibration curve 
# and assign it to the object 'dil'.
dil <- 10^(2: -4)
\end{example}

We previewed the amplification curve raw data using the \code{matplot} 
function (see code below). The amplification curve data showed a strong signal 
level variation in the plateau region (Figure~~\ref{figure:dilution_Cq}A). 
Therefore, all data were subjected to a minimum-maximum normalization (see 
\citet{roediger_RJ_2013}) using the \code{CPP} function from the 
\CRANpkg{chipPCR} package. In addition, all data were baselined and smoothed 
(Figure~~\ref{figure:dilution_Cq}B). The Cq values were calculated by the 
$Cq_{SDM}$ and $Cq_{Ct}$ methods as shown next.

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=12cm]{figures/dilution_Cq.pdf}
  \caption{Analysis of the amplification curve data of the \texttt{guescini1} 
dataset. \strong{(A)} Raw data from the calibration curve samples were visually 
inspected. The qPCR curves display a broad variation in plateau fluorescence 
(38~--~62 RFU). The red horizontal line (\textcolor{red}\textemdash) indicates 
the fluorescence level (0.05) used for the calculation of the Cq value by the 
``cycle threshold'' method. \strong{(B)} The \code{CPP} function from the 
\CRANpkg{chipPCR} was used to baseline the data, to smooth the data with 
Savitzky-Golay smoothing filter and to normalize the data between 0 and 1. 
\strong{(C)} The Cq values were calculated by the $Cq_{SDM}$ method (``SDM 
method'') (\code{inder}, \CRANpkg{chipPCR}) and the $Cq_{Ct}$ method (``Ct 
method'') (\code{th.cyc}, \CRANpkg{chipPCR}). The threshold value was set to 
$r~=~0.05$. The $Cq_{SDM}$ and $Cq_{Ct}$ values were plotted and analysed by a 
linear regression ($R^{2}~=~0.9945$; $P < 2.2^{-16}$) and Pearson's 
($r~=~0.9972605$; $P < 2.2^{-16}$). The amplification efficiency based on 
\strong{(D)} $Cq_{Ct}$ values and \strong{(E)} $Cq_{SDM}$ values were 
automatically analysed with the \code{effcalc} (\CRANpkg{chipPCR}) function. Cq, 
Quantification cycle; SDM, Second derivative maximum, R\textasciicircum2, 
Coefficient of determination; r, Pearson product-moment correlation 
coefficient.}
  \label{figure:dilution_Cq}
\end{figure}

\begin{example}
# Pre-process the amplification curve data with the CPP function from the 
# chipPCR package. The trans parameter was set TRUE to perform a baselining and 
# the method.norm parameter was set to minm for a min-maximum normalization. All
# amplification curves were smoothed by Savitzky-Golay smoothing.

res.CPP <- cbind(gue[, 1], apply(gue[, -1], 2, function(x) {
  CPP(gue[, 1], x, trans = TRUE, method.norm = "minm", method.reg = "least",
      bg.range = c(1,7))[["y.norm"]]
}))

# Use the th.cyc function from the chipPCR package to calculate the Cq values
# by the cycle threshold method at a threshold signal level "r" of 0.05.
Cq.Ct <- apply(gue[, -1], 2, function(x) 
  th.cyc(res.CPP[, 1], x, r = 0.05)[1])

# Use the inder function from the chipPCR package to calculate the Cq values
# by the SDM method.
Cq.SDM <- apply(gue[, -1], 2, function(x)
  summary(inder(res.CPP[, 1], x), print = FALSE)[2])

# Fit a linear model to carry out a regression analysis.
res.Cq <- lm(Cq.Ct ~ Cq.SDM)
\end{example}

To compare the $Cq_{SDM}$ and $Cq_{Ct}$ methods we performed a regression 
analysis. The Cq methods are in a good agreement. However, the dispersion of 
the 
$Cq_{Ct}$ values appeared to be higher than in the $Cq_{SDM}$ values 
(Figure~~\ref{figure:dilution_Cq}C).

\begin{example}
> summary(res.Cq)

Call:
lm(formula = Cq.Ct ~ Cq.SDM)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.4904 -0.2730  0.0601  0.3540  1.1871 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -8.125534   0.207419  -39.17   <2e-16 ***
Cq.SDM       0.988504   0.008097  122.08   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5281 on 82 degrees of freedom
Multiple R-squared:  0.9945,  Adjusted R-squared:  0.9945 
F-statistic: 1.49e+04 on 1 and 82 DF,  p-value: < 2.2e-16
\end{example}

The dilution (``dil'') and the Cq (``Cq.Ct'') values served as input for the 
calculation of the amplification efficiency ($AE$) with \code{effcalc} function 
from the \CRANpkg{chipPCR} package. In our case study we needed to rearrange 
the 
``Cq.Ct'' values in a matrix using the command $effcalc(dil, t(matrix(Cq.Ct, 
nrow = 12, ncol = 7))$. For visualization of the confidence intervals of the 
regression analysis we set the parameter $CI = TRUE$. Finally, Cq values were 
plotted 
using the \code{layout} function (Figure~\ref{figure:dilution_Cq}D~and~E).

\begin{example}
# Store used margin parameters
def.mar <- par("mar")
layout(matrix(c(1,2,3,3,4,5), 3, 2, byrow = TRUE))
# Set bigger top margin.
par(mar = c(5.1, 4.1, 6.1, 2.1))

matplot(gue[, -1], type = "l", lty = 1, col = 1, xlab = "Cycle", 
	    ylab = "RFU", main = "Raw data")
legend("topleft", "A", cex = 3, bty = "n")

matplot(res.CPP[, -1], type = "l", lty = 1, col = 1, xlab = "Cycle", 
	ylab = "RFU", main = "Pre-processed data")
legend("topleft", "B", cex = 3, bty = "n")
abline(h = 0.05, col = "red", lwd = 2)

plot(Cq.SDM, Cq.Ct, xlab = "Ct method", ylab = "SDM method", 
     main = "Comparison of Cq methods")
abline(res.Cq)
legend("topleft", "C", cex = 3, bty = "n")

plot(effcalc(dil, t(matrix(Cq.Ct, nrow = 12, ncol = 7))), CI = TRUE)
legend("topright", "D", cex = 3, bty = "n")

plot(effcalc(dil, t(matrix(Cq.SDM, nrow = 12, ncol = 7))), CI = TRUE)
legend("topright", "E", cex = 3, bty = "n")

# Restore margins to default values.
par(mar = def.mar)
\end{example}

As shown in this case study, it is easy to set-up a streamlined workflow for 
data 
read-in, pre-processing and analysis with a few functions.

\subsection{Case study two -- qPCR and Melting Curve Analysis}

A common task during the analysis of qPCR experiments is to distinguish between 
positive and negative samples (see Figure~\ref{figure:plotCurves}). If the 
melting temperature of a sample is known it is possible to automatize the 
decision by a melting curve analysis (MCA). As shown in \citet{roediger_RJ_2013} 
this can be done by interrogating the $T_{M}$. Therefore, we used a logical 
statement, which tests if $T_{M}$ is within a tight temperature range. We used 
the signal height as second parameter. In line with ``Case study one'' we used 
the function \code{sessionInfo} to track all packages used during the analysis. 
Reproducible research is greatly enhanced if open data exchange formats are 
used. Therefore, we used the \CRANpkg{RDML} package for data read-in. The 
amplification and melting curve data were measured with a CFX96 system (Bio-Rad) 
and then exported as RDML~v~1.1 format file as \file{BioRad\_qPCR\_melt.rdml}. 
Within this qPCR experiment we amplified the \textit{Mycobacterium tuberculosis} 
\textit{katG} gene and tried to detect a mutation at codon 315. The experiment 
was separated in two parts:

\begin{enumerate}
 \item Detection of overall \textit{M.~tuberculosis} DNA (wild-type 
and mutant) and
 \item specific detection of wild-type \textit{M.~tuberculosis} by melting of 
TaqMan probe (quencher -- BHQ2, fluorescent reporter -- Cy5) with amplified DNA 
(see \citet{luo_multiplex_2011} for probe/primer sequences and further details).
\end{enumerate}

The qPCR was conducted using EvaGreen\circledR~Master Mix (Syntol) according to 
the manufacturer's instructions, with 500 nM of primers and probe in a 25 $\mu$L 
final reaction volume. Thermocycling was conducted using a CFX96 (BioRad) 
initiated by 3 min incubation at 95~\textcelsius, followed by 41 cycles (15 s at 
95~\textcelsius; 40 s at 65~\textcelsius) with a single read-out taken at the 
end of each cycle. Probe melting was conducted between 35~\textcelsius~and 
95~\textcelsius~by 1~\textcelsius~at 1 s steps.

The structure of an RDML file is quite complex. Though RDML files are XML 
structured files and thus intended to be readable by humans, it is hard to grasp 
the complex hierarchical file structure with out some basic understanding. A 
simple and fast method to compactly display the structure of object in R is to 
use the \code{str} or \code{summary} function (not shown). However, such R tools 
are not informative in this context. Therefore we implemented a dendrogram like 
view (Figure~\ref{figure:RDML_dendrogram}). According to this, the file contains 
different datasets, each with 3 samples, ('pos',  'ntc', 'unknown'). Only a 
subset of the data was used in our case study and combined to the object 
``qPCR''.

\begin{example}
# Import the qPCR and melting curve data via the RDML package.
# Load the chipPCR package for the pre-processing and curve data quality
# analysis and the MBmca package for the melting curve analysis.
require(RDML)
require(chipPCR)
require(MBmca)
require(dplyr)

# Collect information about the R session used for the analysis of the qPCR
# experiment.
current.session <- sessionInfo()

# Load the BioRad_qPCR_melt.rdml file form RDML package and assign the data to the
# object BioRad.
filename <- paste(path.package("RDML"), "/extdata/", "BioRad_qPCR_melt.rdml", sep = "")
BioRad <- RDML$new(filename)

# Fetch cycle dependent fluorescence for the EvaGreen channel and row 'D'
# (that contains target 'Cy5-2' at channel 'Cy5') of the 
# katG gene and aggregate the data in the object qPCR. 

qPCR <- BioRad$AsTable() %>%
  filter(target == "EvaGreen",
         grepl("^D", position))  %>% 
  BioRad$GetFData(.)
\end{example}

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=13cm]{figures/RDML_dendrogram.pdf}
  \caption{File structure visualization of the RDML file 
\file{BioRad\_qPCR\_melt\.rdml} form the \CRANpkg{RDML} package. The file was read 
by the \code{RDML} function and the structure displayed as dendrogram by the 
call \code{BioRad\$AsDendrogram()}. The names are used according to the RDML 
convention by \citet{lefever_2009}. The object \texttt{BioRad} branches into an 
experiment with \texttt{Run ID} names for two fluorescence detection channels 
(FAM, Cy5). The targets have typical designations like \texttt{pos} (positive), 
\texttt{unkn} (unknown) and \texttt{ntc} (non-template control). In the deeper 
branches are the data types \texttt{adp} (amplification data point) and 
\texttt{mdp} (melting data point) shown with the number of samples (ranging from 
2 to 18).
} 
\label{figure:RDML_dendrogram}
\end{figure}

We inspected and pre-processed a subset of the amplification curve data solely 
using functionalities provided by the \CRANpkg{chipPCR} package. The 
\code{plotCurves} function was used to get an overview of the curvatures. The 
data indicated a baseline shift in all curves with a slight negative trend 
(Figure~\ref{figure:plotCurves}). This observation suggested to baseline the raw 
data by using a linear regression model (cycles x - y; ($bg.range = c(x, y)$) in 
the \code{CPP} function.). The curvatures of ``D1\_Alm12\ldots'' and 
``D2\_Alm12\ldots'' exhibited a drop in the plateau phase. However, this is not 
of importance during this stage of the analysis.

\begin{example}
# Use plotCurves function to get an overview of the amplification curve samples.

plotCurves(qPCR[, 1], qPCR[, -1], type = "l")

# Detect positive samples - calculate Cq values by the cycle threshold method. 
# The threshold signal level r was set to 10.
Cq.Positive <- t(apply(qPCR[, -1], 2, function(x)
{
  res <- CPP(qPCR[, 1], x, trans = TRUE, bg.range = c(2, 8),
             method.reg = "least")[["y.norm"]]
  # The th.cyc fails when the threshold exceeds maximum 
  # observed fluorescence values, so it must be used with try()
  th.cycle <- try(th.cyc(qPCR[, 1], res, r = 10)[1], silent = TRUE)
  cq <- ifelse(class(th.cycle) != "try-error", as.numeric(th.cycle), NA)
  pos <- !is.na(cq)
  c(Cq=cq, M.Tub_positive = pos)
}
))
Cq.Positive
\end{example}

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=12cm]{figures/plotCurves.pdf}
  \caption{Analysis of the amplification curve data. The calibration curve 
samples were inspected by the \code{plotCurves} function from the 
\CRANpkg{chipPCR} package. The green color code indicates that the data contain 
no missing values. However, the visual inspection revealed that the data are 
noisy. All samples (``D1\_Alm12\ldots'' - ``D8\_Alm12\ldots'') appeared to be 
positive. One negative control (``D10\_H20\_ntc\_EvaGreen'') 
seems to be contaminated.}
  \label{figure:plotCurves}
\end{figure}

Since the amplification curves indicated that selected samples (except 
non-template-control (``NTC'')) are positive, we distinguished between true 
positive and true negative samples by MCA (Figure~\ref{figure:amp_melt}A).

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14.5cm]{figures/amp_melt.pdf} 
\caption{Amplification curve plots and melting curve plots. \strong{(A)} The raw 
amplification curve data were pre-processed with the \code{CPP} function prior 
to visualization. To calculate the $T_{M}$ values from the raw melting curve 
data \strong{(B)} we used the \code{diffQ} function from the \CRANpkg{MBmca} 
package. \strong{(C)} We adjusted our algorithm to plot the true positive 
melting peaks in red, while negative melting peaks were labelled in black. The 
inspection of the plot and the output of \texttt{results.tab} showed that only 
D07\_katG 315\_unkn\_EvaGreen (\textcolor{red}\textemdash) and D08\_katG 
315\_unkn\_EvaGreen (\textcolor{red}\textemdash) are true positive. RFU, 
relative fluorescence units; -d(RFU)/dT, negative first derivative of the melting-curve.} 
\label{figure:amp_melt}
\end{figure}

\begin{example}
# Fetch temperature dependent fluorescence for the Cy5 channel of the 
# probe that can hybridize with Mycobacterium tuberculosis katG gene (codon 315)
# and aggregate the data in the object 'melt'.
melt <- BioRad$AsTable() %>%
        filter(target == "Cy5-2")  %>% 
        BioRad$GetFData(., data.type = "mdp")

# Calculate the melting temperature with the diffQ function from the MBmca 
# package. Use simple logical conditions to find out if a positive sample with 
# the expected Tm of circa 54.5 degree Celsius is found. The result of the test
# is assigned to the object 'positive'.
Tm.Positive <- matrix(nrow = ncol(melt) - 1,
                      byrow = TRUE,
                      dimnames = list(colnames(melt)[-1]),
                      unlist(apply(melt[, -1], 2, function(x) {
                        res.Tm <- diffQ(cbind(melt[, 1], x), 
                                        fct = max, inder = TRUE)
                        positive <- ifelse(res.Tm[1] > 54 & 
                                             res.Tm[1] < 55 & 
                                             res.Tm[2] > 80, 1, 0)
                        c(res.Tm[1], res.Tm[2], positive)
                      })))


# Present the results in a tabular output as data.frame 'results.tab'.
# Result of analysis logic is:
# Cq.Positive && Tm.Positive = Wild-type
# Cq.Positive && !Tm.Positive = Mutant
# !Cq.Positive && !Tm.Positive = NTC
# !Cq.Positive && Tm.Positive = Error
results <- sapply(1:length(Cq.Positive[, 1]), function(i) {
  if(Cq.Positive[i, 2] == 1 && Tm.Positive[i, 3] == 1)
    return("Wild-type")
  if(Cq.Positive[i, 2] == 1 && Tm.Positive[i, 3] == 0)
    return("Mutant")
  if(Cq.Positive[i, 2] == 0 && Tm.Positive[i, 3] == 0)
    return("NTC")
  if(Cq.Positive[i, 2] == 0 && Tm.Positive[i, 3] == 1)
    return("Error")
})

results.tab <- data.frame(cbind(Cq.Positive, Tm.Positive, results))
names(results.tab) <- c("Cq", "M.Tub DNA", "Tm", "Height", 
                        "Tm positive", "Result")

results.tab[["M.Tub DNA"]] <- factor(results.tab[["M.Tub DNA"]], 
                                     labels=c("Not Detected", "Detected"))

results.tab[["Tm positive"]] <- factor(results.tab[["Tm positive"]], 
                                       labels=c(TRUE, FALSE))
results.tab
\end{example}

The results of the analysis can be invoked by the statement $results.tab$ (not 
shown). Finally, we plotted and printed the output of our melting curve 
(Figure~\ref{figure:amp_melt}B) and melting peak (Figure~\ref{figure:amp_melt}C) 
analysis.

\begin{example}
# Convert the decision from the results.tab object in a color code:
# Negative, black; Positive, red.

color <- c(Tm.Positive[, 3] + 1)

# Arrange the results of the calculations in plot.
layout(matrix(c(1,2,1,3), 2, 2, byrow = TRUE))

# Use the CPP function to preporcess the amplification curve data.
plot(NA, NA, xlim = c(1, 41), ylim = c(0,200), xlab = "Cycle", ylab = "RFU")
mtext("A", cex = 2, side = 3, adj = 0, font = 2)
lapply(2L:ncol(qPCR), function(i) 
  lines(qPCR[, 1], 
        CPP(qPCR[, 1], qPCR[, i], trans = TRUE, 
            bg.range = c(1,9))[["y.norm"]],
        col = color[i - 1]))

matplot(melt[, 1], melt[, -1], type = "l", col = color, 
        lty = 1, xlab = "Temperature [degree Celsius]", ylab = "RFU")
mtext("B", cex = 2, side = 3, adj = 0, font = 2)

plot(NA, NA, xlim = c(35, 95), ylim = c(-15, 120), xlab = "Temperature [degree Celsius]", 
     ylab = "-d(RFU)/dT")
mtext("C", cex = 2, side = 3, adj = 0, font = 2)

lapply(2L:ncol(melt), function(i)
  lines(diffQ(cbind(melt[, 1], melt[, i]), verbose = TRUE, 
              fct = max, inder = TRUE)[["xy"]], col = color[i - 1]))
\end{example}

According to the analysis by MCA the samples ``D07\_katG315\ldots'' and 
``D08\_katG315\ldots'' were the only positive. The remaining samples appeared to 
be positive in the amplification plot in Figure~\ref{figure:plotCurves} due to 
primer-dimer formation or sample contamination.

\subsection{Case study three -- Isothermal Amplification}

Isothermal amplification is an alternative to PCR, which uses a constant 
temperature rather than cycling through denaturation, annealing and extension 
steps \citep{rodiger_nucleic_2014}. The corresponding signal is monitored 
continuously on a time basis. Often the abscissa values are not uniformly 
spaced\footnote{The \texttt{C81} example datasets chosen in this case study are 
not uniformly spaced. The \code{CPP} function gives a warning in such a case.}. 
In qIA the $Cq$ values are dependent on the time instead of cycles. In this 
study we used the \code{th.cyc} function from the \CRANpkg{chipPCR} package to 
determine the time ($Cq_{t}$) required to reach a defined threshold signal 
level.

We performed a quantitative isothermal amplification (qIA) with the plasmid 
\textit{pCNG1} by using a Helicase Dependent Amplification (HDA). Our previously 
reported VideoScan platform \citep{rodiger_highly_2013} was used to control the 
temperature and to monitor the amplification reaction. The VideoScan technology 
is based on a highly versatile fluorescence microscope imaging platform, which 
can be operated with a heating/cooling unit (HCU) for qPCR and MCA applications 
\citep{roediger_RJ_2013, rodiger_highly_2013}. Since the enzyme DNA Helicase 
unwinds DNA, no thermal denaturation is needed. The HDA conditions were taken 
from the ``IsoAmp III Universal tHDA Kit'', Biohelix Corp, as described by the 
vendor. In detail, the reaction was composed of ``mix A'' 10 $\mu$L A. bidest, 
1.25 $\mu$L 10X~buffer, 0.75 $\mu$L primer (150 nM final), 0.5 $\mu$L template 
plasmid. Preincubation: The mixture was incubated for 2 min at 
95\textcelsius~and immediately placed on ice. Reaction ``mix B'' contained 5 
$\mu$L A. bidest., 1.25 $\mu$L 10X buffer, 2 $\mu$L NaCl, 1.25 $\mu$L 
$MgSO_{4}$, 1.75 $\mu$L dNTPs, 0.25 $\mu$L EvaGreen (Biotium), 1 $\mu$L enzyme 
mix. The mix was covered with 50 $\mu$L mineral oil (Roth). The fluorescence 
measurement in VideoScan HCU started directly after adding ``mix B'' at 
65\textcelsius. A $1x$ (D1) and a $1:10$ dilution (D2) were tested. The 
resulting dataset \texttt{C81} is part of the \CRANpkg{chipPCR} package. Two 
concentrations (stock and 1:10 diluted stock) of input DNA were used in the HDA. 
Similar to the previous case studies, we first prepared the plot of the data. 
Since the raw data showed a slight negative trend and an off-set of circa 0.45 
MFI (mean fluorescence intensity) it was necessary 
to pre-process the raw data (Figure~\ref{figure:qIA}A). First we had a look at 
the C81 dataset with the \code{str} function.

\begin{example}
str(C81)
'data.frame':	351 obs. of  5 variables:
 $ Cycle : int  0 1 2 3 4 5 6 7 8 9 ...
 $ t.D1  : int  0 51 73 90 107 124 140 157 174 190 ...
 $ MFI.D1: num  0.549 0.535 0.532 0.53 0.525 ...
 $ t.D2  : int  0 19 53 72 91 110 128 147 166 185 ...
 $ MFI.D2: num  0.77 0.523 0.514 0.51 0.508 ...
\end{example}

The data are arranged in a data frame. The first column contains the measure 
point (cycle) and the consecutive columns the time stamps (seconds) and the 
signal hight (as MFI). A brief look at the time stamps (e.g., ``t.D1'') showed 
that the data were not measured equidistant. Next we plotted and analysed the 
data. 

\begin{figure}[htbp]
  \centering
  \includegraphics[clip=true, width=14.5cm]{figures/qIA.pdf}
  \caption{Quantitative isothermal amplification by Helicase Dependent 
Amplification (HDA). \strong{(A)} The raw data of the HDA (D1, undiluted, D2 
$1:10$ diluted) exhibit some outliers (detector artifacts), an off-set of circa 
0.5 MFI and a slight negative trend in the 
baseline region (0~-~52 minutes). \strong{(B)} First we used the \code{CPP} 
function to smooth the data with a spline function. Baselining was done with a 
linear regression model (robust MM-estimator). Finally, we used the 
\code{th.cyc} function (\CRANpkg{chipPCR}) to calculate the cycle threshold time 
for samples D1 and D2. The threshold value was set to $r = 0.05$ ($--$, 
threshold line). $Cq_{t}$, required time to reach a defined threshold signal 
level. MFI, mean fluorescence intensity.}
  \label{figure:qIA}
\end{figure}

\begin{example}
# Drawn in an 2-by-1 array on the device by two columns and one row.
par(mfrow = c(2, 1))

# Plot the raw data from the C81 dataset to the first array and add
# a legend. Note: The abscissa values (time in seconds) was divided 
# by 60 (C81[, i] / 60) to convert to minutes.
plot(NA, NA, xlim = c(0, 120), ylim = c(0, 1.2), xlab = "Time (min)", ylab = "MFI")
mtext("A", cex = 2, side = 3, adj = 0, font = 2)
lapply(c(2, 4), function(i) {
  lines(C81[, i] / 60, C81[, i + 1], type = "b", pch = 20, col = i - 1)
})
legend(10, 0.8, c("D1: 1x", "D2: 1:10 diluted sample"), pch = 19, col = c(1,3), bty = "n")

# Prepare a plot on the second array for the pre-processed data.
plot(NA, NA, xlim = c(0, 120), ylim = c(0, 1.2), xlab = "Time (min)", ylab = "MFI")
mtext("B", cex = 2, side = 3, adj = 0, font = 2)
\end{example}

First, we used the \code{CPP} function to pre-process the raw data. Similar to 
the other case studies we baselined and smoothed the amplification curve data 
prior to the analysis of the of the $Cq_{t}$ value. However, instead of the 
Savitzky-Golay smoother we used a cubic spline ($method = "spline"$) in the 
\code{CPP} function. In addition, outliers were automatically removed in the 
baseline region (Figure~\ref{figure:qIA}A~and~B). The background range was 
defined by bare eye to be between the $1^{th}$ and $190^{th}$ data point 
(corresponds to baseline region between 0~and~52 minutes). 

\begin{example}
# Apply the CPP functions to pro-process the raw data.1) Baseline data to zero, 
# 2) Smooth data with a spline, 3) Remove outliers in background range between 
# entry 1 and 190. Assign the results of the analysis to the object 'res'.

res <- lapply(c(2, 4), function(i) {
  y.s <- CPP(C81[, i] / 60, C81[, i + 1],
             trans = TRUE, 
             method = "spline",
             bg.outliers = TRUE,
             bg.range = c(1, 190))
  lines(C81[, i] / 60, y.s[["y.norm"]], type = "b", pch = 20, col = i - 1)
  # Use the th.cyc function to calculate the cycle threshold time (Cq.t). 
  # The threshold signal level r was set to 0.05. NOTE: The function th.cyc
  # will give a warning in case data are not equidistant. This is intentional
  # to make the user aware of potential artificats due to pre-processing.
  paste(round(th.cyc(C81[, i] / 60, y.s[["y.norm"]], r = 0.05)[1], 2), "min")
})

# Add the cycle threshold time from the object 'res' to the plot.

abline(h = 0.05, lty = 2)
text(10, 0.55, "Cq.t:")
legend(10, 0.5, paste(c("D1: ", "D2: "), res), pch = 19, col = c(1, 3), 
       bty = "n")
\end{example}

The pre-processed data were subjected to the analysis of the $Cq_{t}$ values. 
It is important to note that the trend correction and proper baseline was a 
requirement for a sound calculation. We calculated $Cq_{t}$ values of 
70.18~minutes and 93.18 minutes for the stock (D1) and 1:10 (D2) diluted 
samples, receptively.

\subsection{Case study four - digital PCR}

We have developed the \CRANpkg{dpcR} package for analysis and presentation of 
digital PCR experiments. The \CRANpkg{dpcR} package can be used to build 
custom-made analysis pipelines and provides structures to be openly extended by 
the scientific community. Simulations and predictions of binomial and Poisson 
distributions, commonly used theoretical models of dPCR, statistical data 
analysis methods, plotting facilities and report generation tools are part of 
the package \citep{pabinger_2014}. Here, we show a case study for the 
\CRANpkg{dpcR} package. Simulations are part in many educational curricula and 
greatly support teaching. In this case study, we mimicked an \textit{in silico} 
experiment for a droplet digital PCR similar to Figure~\ref{figure:dpcR_sim}. 
The aim was to assess the concentration of the template sample. In the following 
we will use the expression partition as synonym for droplet. The number of 
positive partitions ($k$), total number of partitions ($n$) and the size of the 
partition are the only data required for the analysis. The estimate of the mean 
number of template molecules per partition ($\hat \lambda$) was calculated using 
following equation \citep{huggett_2013}:

\begin{equation}
\hat{\lambda} =  -\ln{(1 - \frac{k}{n})}.
\end{equation}

The average partition volume in our experiment was assumed to be 5 nL. We 
counted $n = 16800$ partitions in total from which $k = 4601$ partitions were 
positive. The binomial distribution of positive and negative partitions was used 
to determine $\hat \lambda$ (Figure~\ref{figure:dpcR}). Our packages allows both 
easy estimation of a density of the parameter and calculation of confidence 
intervals using Wilson's method \citep{brown_2001} at a confidence interval 
level of 0.95. The obtained mean number of template molecules per partition 
multiplied by the volume of the partitions ($ 16800 * 5~nL$) constitutes the 
sample concentration.

\begin{example}
# Load the dpcR package for the analysis of the digital PCR experiment.
require(dpcR)

# Analysis of a digital PCR experiment. The density estimation.
# In our in silico experiment we counted in total 16800 partitions (n). 
# Thereof, 4601 were positive (k).

(dens <- dpcr_density(k = 4601, n = 16800, average = TRUE, methods = "wilson"))

# Let us assume, that every partition has roughly a volume of 5 nL.
# The total concentration (and its confidence intervals) in molecules/mL is
# (the factor 1e-6 is used for the conversion from nL to mL):
dens[4:6] / 5 * 1e-6
\end{example}

\begin{figure}[h]
  \centering
  \includegraphics[clip=true, width=7cm]{figures/dpcR.pdf}
  \caption{\code{dpcr\_density} function from the \CRANpkg{dpcR} package used 
for analysis of droplet digital PCR experiment. From 16800 counted partitions 
($n$) 4601 were positive ($k$). The chart presents the distribution of mean 
number of template molecules per partition ($\hat \lambda$). $n$, number of 
total partitions; $k$, number of positive partitions.
}
  \label{figure:dpcR}
\end{figure}

Since we assumed a partition volume of 5 nL we have a total volume of 0.084~mL 
an $6.40^{-8}$ (95\% CI: $6.2^{-8}$ - $6.6^{-8}$) molecules/mL in the 
sample.

Selected functionality was implemented as interactive \CRANpkg{shiny} GUI 
application to make the software accessible for users who are not fluent in R 
and for experts who wish to automatize routine tasks. Details and examples of 
the \CRANpkg{shiny} web application framework for R can be found at 
\url{http://shiny.rstudio.com/}. We implemented flexible user interfaces, which 
run the analyses and graphical representation into interactive web applications 
either as service on a web server or on a local machine without knowledge of 
HTML or ECMAScript (see \CRANpkg{dpcR} manual). The interface is designed in a 
cascade workflow approach (Data import $\rightarrow$ Analysis $\rightarrow$ 
Output $\rightarrow$ Export) with interactive users choice on input data, 
methods and parameters using typical GUI elements such as sliders, drop-downs 
and text fields. An example can be found at 
\url{https://michbur.shinyapps.io/dpcr_density/}. This approach enables the 
automatized output of R objects in combined plots, tables and summaries.

\subsection{Case study five - digital PCR correction}

There is an ongoing debate in the scientific community about the effect of the 
partition volume on the estimated copy numbers size 
\citep{huggett_clinchem_2014, corbisier_2015, majumdar_2015}. 
\citet{corbisier_2015} showed that the partition volume is a critical parameter 
for the measurement of copy number concentrations. Their study revealed that the 
average droplet volume defined in the QuantaSoft software (v.~1.3.2.0, BioRad 
QX100 Droplet Digital PCR System) is 8~\% lower than the real volume. In 
consequence, results of quantifications were systematically biased between 
different dPCR platforms. 

Case study four served as an introduction into the analysis of simulated dPCR 
experiments with the \CRANpkg{dpcR} package. In the next case study, number 
five, we used the \texttt{pds\_raw} dataset, which was generated by a BioRad 
QX100 Droplet Digital PCR System experiment. We re-analysed the data with the 
partition volume of 0.834~nL as proposed by \citet{corbisier_2015} and a volume 
of 0.90072~nL as used in the BioRad QX100 Droplet Digital PCR System.

Our experimental setup was as follows. A duplex assay was used to simultaneously 
detect a constant amount of genomic DNA (theoretically $10^{2}$ copies/$\mu$L) 
and a variable amount of plasmid DNA (10-fold serial dilution, not shown). The 
genomic DNA was isolated from \textit{Pseudomonas putida KT2440} and the plasmid 
was \textit{pCOM10-StyA::EGFP StyB}. Template DNA was heat treated at 
95\textcelsius~for 5 min prior to PCR. Channel~1, primers for genomic DNA marker 
\textit{ileS}, Taqman probes (FAM labelled). Channel~2, primers for plasmid DNA 
marker \textit{styA}, Taqman probes (HEX labelled) (see \citep{jahn_2013, 
jahn_2014} and the manual of the \CRANpkg{dpcR} package for details). Gating and 
partition clustering was taken without any modification from the data output of 
the BioRad QX100 Droplet  Digital PCR System. Each partition is represented by a 
dot in Figure~\ref{figure:dpcR_bioamp}. First, we had a look at the data 
structure of the \texttt{pds\_raw} dataset.

\begin{example}
# Load the dpcR package and use the pds_raw dataset for the analysis of the 
# digital PCR experiment.
require(dpcR)

# To get an overview of the dataset we used the head and summary R functions.
head(summary(pds_raw))

# The output shows that the dataset contains lists of different samples (A01 ...)
    Length Class        Mode  
A01 "3"    "data.frame" "list"
A02 "3"    "data.frame" "list"
A03 "3"    "data.frame" "list"
A04 "3"    "data.frame" "list"
B01 "3"    "data.frame" "list"
B02 "3"    "data.frame" "list"

# Next we used str for the element A01. The element of the list contains a data frame
# with three columns. Two contains Amplitude values (fluorescence intensity) and one
# contains cluster resultes (interger values of 1 - 4).

str(pds_raw[["A01"]])
'data.frame':	11964 obs. of  3 variables:
 $ Assay1.Amplitude: num  397 399 402 416 417 ...
 $ Assay2.Amplitude: num  3732 3808 4007 3778 3685 ...
 $ Cluster         : int  4 4 4 4 4 4 4 4 4 4 ...
\end{example}

Since the structure of the dataset was known now we selected samples for the 
analysis. According to the \CRANpkg{dpcR} manual contain the samples ``A02'', 
``B02'', ``C02'' and ``D02'' the values for the replicates at a 1:100 dilution 
and ``G04'' the values for the non-template control.

\begin{example}
# Select the wells for the analysis. A01 to D01 are four replicate dPCR reactions 
# and G04 is the no template control (NTC).
wells <- c("A02", "B02", "C02", "D02", "G04")

# Set the arrangement for the plots. The first column contains the amplitude 
# plots, column two the density functions and column three the concentration
# calculated on according to the droplet volume as defined in the QX100 system,
# or the method proposed by Corbisier et al. (2015).
par(mfrow = c(5,3))

# The function bioamp was used in a loop to extract the number of positive and negative 
# partitions from the sample files. The results were assigned to the object 'res' and plotted.
# Horizontal and vertical lines show the threshold borders as defined by the QX100 system. 

for (i in 1L:length(wells)) {
  cluster.info <- unique(pds_raw[wells[i]][[1]]["Cluster"])
  res <- bioamp(data = pds_raw[wells[i]][[1]], amp_x = 2, amp_y = 1, 
		main = paste("Well", wells[i]), xlab = "Amplitude of ileS (FAM)",
		ylab = "Amplitude of styA (HEX)", xlim = c(500,4700), 
		ylim = c(0,3300), pch = 19)
  # Draw threshold line to visualize between positive and negative partitions.
  abline(h = max(with(pds_raw[wells[i]][[1]], 
		 subset(Assay1.Amplitude, Cluster == 4))), lty = 2)
  abline(v = min(with(pds_raw[wells[i]][[1]], 
		 subset(Assay2.Amplitude, Cluster == 4))), lty = 2)
  legend("topright", as.character(cluster.info[, 1]), col = cluster.info[, 1], pch = 19)
\end{example}

Next we used the results from the object \texttt{res} to get the information 
about the number positive partitions for the  plasmid DNA marker \textit{styA}. 
This is to be found in the clusters 2 and 3.

\begin{example}
  # Counts for the positive clusters 2 and 3 were assigned to new objects and further used by
  # the function dpcr_density to calculate the number of molecules per partition and the 
  # confidence intervals. The results were plotted as density plot.
  k.tmp <- sum(res[1, "Cluster.2"], res[1, "Cluster.3"])
  # Counts for all clusters
  n.tmp <- sum(res[1, ])
  
  dens <- dpcr_density(k = k.tmp, n = n.tmp, 
			average = TRUE, methods = "wilson")
  legend("topright", paste("k:", k.tmp,"\nn:", n.tmp))
  
  # Finally, the concentration of the molecules was calculate with the volume used in 
  # the QX100 system and as proposed by Corbisier et al. (2015).The results were added
  # as barplot with the confidence intervals.
  
  res.conc <- rbind(original = dens[4:6] /  0.90072 * 1e-6, 
		    corrected = dens[4:6] / 0.834 * 1e-6)
  barplot(res.conc[, 1], col = c("white","grey"), 
	  names = c("Bio-Rad", "Corbisier"), 
	  main = "Influence of\nDroplet size", ylab = "molecules/ml", 
	  ylim = c(0,1.5*10E-8))
    arrows(c(0.7,1.9), res.conc[, 2], c(0.7,1.9), res.conc[, 3], angle = 90, 
	   code = 3, lwd = 2)
}
\end{example}

\begin{figure}[h]
\centering
  \includegraphics[clip=true, width=12cm]{figures/dpcR_bioamp.pdf}
    \caption{Analysis of a droplet digital PCR experiment. We used the 
\texttt{pds\_raw} dataset from the \CRANpkg{dpcR} package. All raw data were 
generated with a BioRad QX100 Droplet Digital PCR System. Column one: Amplitude 
plot of raw data shown by the \code{bioamp} function. Each dot represents a 
partition in a cluster. Negative partition are below and positive partitions above the 
dashed line ({\textbf{\textendash\textendash}}). 
$Cluster~1$~\textcolor{black}{\textbf{\textbullet}}, 
$Cluster~2$~\textcolor{red}{\textbf{\textbullet}}~=~Target, 
$Cluster~3$~\textcolor{green}{\textbf{\textbullet}}~=~Target, 
$Cluster~4$~\textcolor{blue}{\textbf{\textbullet}}. Well~A01~-~D04 are replicate 
measurements and Well~G04 is the negative control; Column two: Density function 
with showing the number of molecules per partition. All replicates had similar 
numbers of counted positive partitions ($k$) and total number of partitions ($n$); 
Column three: Concentration of DNA molecules based on the volume used by the 
BioRad QX100 Droplet Digital PCR System and the volume proposed by 
\citet{corbisier_2015}. 
    }  \label{figure:dpcR_bioamp}
\end{figure}

Our results show, that the replicates in 
Figure~\ref{figure:dpcR_bioamp}~A01~-~D01 vary. However, the variation is within 
a similar range (Figure~\ref{figure:dpcR_bioamp}~column~2). The positive samples 
differ significantly from the negative control 
(Figure~\ref{figure:dpcR_bioamp}~G04). As proposed by \citet{corbisier_2015} the 
analysis with the non-corrected droplet volume leads to an underestimation of 
sample concentrations (Figure~\ref{figure:dpcR_bioamp}~column~3). However, our 
case studies shows, that the R environment can be used to circumvent problems of 
locked-in systems.

\section{Discussion and Conclusion}

This study gave a brief introduction to the analysis of qPCR, qIA, MCA and dPCR 
experiments with R. In addition to this, we briefly referenced to a vast 
collection of additional packages available from CRAN and Bioconductor. The 
packages may be considered as the building blocks (libraries) to create what 
users want and need. We showed that automatized research with R offers powerful 
means for statistical analysis and visualization. The software is not tied to a 
vendor or specific application (e.g., chamber or droplet based digital PCR, 
capillary or plate qPCR). It should be quite easy even for an inexperienced user 
to define a workflow and to set up an environment for specific needs in a broad 
range of technical settings (Figure~\ref{figure:options}). R enforces no 
monolithic integration. We claim that the modular structure of R packages allows 
the user to perform flexible data analysis, adjusted to their needs and to 
design frameworks for high-throughput analysis. Furthermore, R enables the user 
to access and reuse code for the creation of reports in various formats (e.g., 
HTML, PDF).

\begin{figure}[h]
  \centering
  \includegraphics[clip=true, width=10cm]{figures/options.png}
  \caption{Deployment of R applications for the qPCR and dPCR experiments. 
\strong{(A)} R is typically run from a desktop computer an operated by an 
GUI/IDE application such as \pkg{RStudio} or \pkg{RKWard}. This approach 
provides a flexible workflow for individuals. \strong{(B)} Another approach is 
to run R with specific applications on a local server. Such scenarios are 
useful 
for the deployment within research departments or cooperate units 
\citep{R_web}. 
\strong{(C)} Cloud computing (CC) provides shared and scalable computing 
capacity (e.g., computing capacity, application software) and storage capacity 
(e.g., databases) as a service to an individual user or a community Service 
categories include: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service 
(PaaS) and Software-as-a-Service (SaaS) over a network. Providers of CC manage 
the infrastructure and resources to achieve coherence and economies of scale 
similar to a utility over a network (i.~p., Internet) \citep{R_cloud}.}
  \label{figure:options}
\end{figure} 

Most of the software is cross-platform open source software. Despite the fact 
that R is free of charge, it is quite possible to build commercial applications. 
The packages cover implementation of novel approaches and peer-reviewed analysis 
methods. R packages are an open environment to adopt to the growing knowledge in 
life sciences and medical sciences. Therefore, we argue that R may provide a 
structure for standardized nomenclature and serve as reference in qPCR and dPCR 
analysis. Speaking about openness, it needs to be emphasized that the main 
advantage of this software is its transparency at any time for anybody. Thus, it 
is possible to track numerical errors.  A disadvantage of R is the lack of 
comprehensive GUIs for qPCR analysis. We believe that a graphical user interface 
(GUI) is a key technology to spread the use of R in bioanalytical sciences. 
Currently, we are establishing the ``pcRuniveRsum'' 
(\url{http://michbur.github.io/pcRuniveRsum/}) as an on-line resource for the 
interested users. The command-line structure makes R ``inaccessible'' for many 
novices. We try to solve this problem with easily accessible GUIs 
\citep{rodiger_rkward_2012}. However, the work on this additions has been 
recently started and is still in progress.

\section{Acknowledgment}

Part of this work was funded by the BMBF InnoProfile-Transfer-Projekt 03 IPT 
611X, the European Regional Development Fund (ERDF/EFRE) on behalf of the 
European Union, the S\"{a}chsische Aufbaubank (Free State of Saxony, 
Germany) and the Russian Ministry of Education and Science (project No. 
RFMEFI62114X0003) and with usage of scientific equipment of Center for 
collective use ``Biotechnology'' at All-Russia Research Institute of 
Agricultural Biotechnology. We would like to thank the R community. We would 
like to thank Mario Menschikowski (Technical University Dresden) for the droplet 
digital PCR samples. 

\bibliography{roediger-burdukiewicz-blagodatskikh-schierack}

\address{Stefan R\"odiger (corresponding author)\\
  Faculty of Natural Sciences\\
  Brandenburg University of Technology Cottbus--Senftenberg\\
  Senftenberg\\
  Germany}
\email{Stefan.Roediger@b-tu.de}

\address{Micha\l{} Burdukiewicz\\
  University of Wroclaw\\
  Faculty of Biotechnoloy\\
  Department of Genomics\\
  Wroclaw\\
  Poland}
\email{michalburdukiewicz@gmail.com}

\address{Konstantin Blagodatskikh\\
  All-Russia Research Institute of Agricultural Biotechnology\\
  Center for collective use ``Biotechnology''\\
  Moscow\\
  Russia}
\email{k.blag@yandex.ru}

\address{Michael Jahn\\
  Helmholtz Centre for Environmental Research - UFZ\\
  Flow cytometry group / Environmental microbiology\\
  Leipzig\\
  Germany}
\email{michael.jahn@ufz.de}

\address{Peter Schierack\\
  Faculty of Natural Sciences\\
  Brandenburg University of Technology Cottbus--Senftenberg\\
  Senftenberg\\
  Germany}
\email{Peter.Schierack@hs-lausitz.de}
